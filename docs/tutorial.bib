@book{borensteinIntroductionMetaAnalysis2009,
  title = {Introduction to {{Meta-Analysis}}},
  author = {Borenstein, Michael and Hedges, Larry V. and Higgins, Julian P. T. and Rothstein, Hannah R.},
  date = {2009},
  publisher = {John Wiley \& Sons, Ltd},
  doi = {10.1002/9780470743386},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/9780470743386.refs/summary},
  isbn = {978-0-470-74338-6},
  langid = {english},
  keywords = {meta-analysis,Meta-Analysis as Topic},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\8U6XAR8B\\Borenstein - Introduction to Meta-analysis.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\R975CG6N\\summary.html}
}

@book{hastieElementsStatisticalLearning2009,
  title = {The Elements of Statistical Learning: {{Data}} Mining, Inference, and Prediction},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  date = {2009},
  edition = {Second},
  publisher = {Springer},
  location = {New York},
  file = {C:\Users\vanlissa\Zotero\storage\9SNFR93Q\Elements of statistical learning.pdf}
}

@article{higginsControllingRiskSpurious2004,
  title = {Controlling the Risk of Spurious Findings from Meta-Regression},
  author = {Higgins, Julian P. T. and Thompson, Simon G.},
  date = {2004},
  journaltitle = {Statistics in Medicine},
  volume = {23},
  number = {11},
  pages = {1663--1682},
  doi = {10.1002/sim.1752},
  url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.1752/full},
  urldate = {2017-08-16},
  file = {C:\Users\vanlissa\Zotero\storage\YCXWZEG8\higgins2004.pdf}
}

@article{higginsReevaluationRandomeffectsMetaanalysis2009,
  title = {A Re-Evaluation of Random-Effects Meta-Analysis},
  author = {Higgins, Julian P. T. and Thompson, Simon G. and Spiegelhalter, David J},
  date = {2009-01},
  journaltitle = {Journal of the Royal Statistical Society. Series A, (Statistics in Society)},
  shortjournal = {J R Stat Soc Ser A Stat Soc},
  volume = {172},
  number = {1},
  eprint = {19381330},
  eprinttype = {pmid},
  pages = {137--159},
  issn = {0964-1998},
  doi = {10.1111/j.1467-985X.2008.00552.x},
  url = {http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2667312/},
  abstract = {Meta-analysis in the presence of unexplained heterogeneity is frequently undertaken by using a random-effects model, in which the effects underlying different studies are assumed to be drawn from a normal distribution. Here we discuss the justification and interpretation of such models, by addressing in turn the aims of estimation, prediction and hypothesis testing. A particular issue that we consider is the distinction between inference on the mean of the random-effects distribution and inference on the whole distribution. We suggest that random-effects meta-analyses as currently conducted often fail to provide the key results, and we investigate the extent to which distribution-free, classical and Bayesian approaches can provide satisfactory methods. We conclude that the Bayesian approach has the advantage of naturally allowing for full uncertainty, especially for prediction. However, it is not without problems, including computational intensity and sensitivity to a priori judgements. We propose a simple prediction interval for classical meta-analysis and offer extensions to standard practice of Bayesian meta-analysis, making use of an example of studies of ‘set shifting’ ability in people with eating disorders.},
  pmcid = {PMC2667312},
  file = {C:\Users\vanlissa\Zotero\storage\9RPWEBFF\Higgins et al. - 2009 - A re-evaluation of random-effects meta-analysis.pdf}
}

@article{higginsStatisticalHeterogeneitySystematic2002,
  title = {Statistical Heterogeneity in Systematic Reviews of Clinical Trials: A Critical Appraisal of Guidelines and Practice},
  shorttitle = {Statistical Heterogeneity in Systematic Reviews of Clinical Trials},
  author = {Higgins, Julian and Thompson, Simon and Deeks, Jonathan and Altman, Douglas},
  date = {2002-01-01},
  journaltitle = {Journal of Health Services Research \& Policy},
  shortjournal = {J Health Serv Res Policy},
  volume = {7},
  number = {1},
  pages = {51--61},
  publisher = {SAGE Publications},
  issn = {1355-8196},
  doi = {10.1258/1355819021927674},
  url = {https://doi.org/10.1258/1355819021927674},
  urldate = {2024-10-16},
  abstract = {Objective: Heterogeneity between study results can be a problem in any systematic review or meta-analysis of clinical trials. Identifying its presence, investigating its cause and correctly accounting for it in analyses all involve difficult decisions for the researcher. Our objectives were: to collate recommendations on the subject of dealing with heterogeneity in systematic reviews of clinical trials; to investigate current practice in addressing heterogeneity in Cochrane reviews; and to compare current practice with recommendations.Methods: We review guidelines for those undertaking systematic reviews and examine how heterogeneity is addressed in practice in a sample of systematic reviews, and their protocols, from the Cochrane Database of Systematic Reviews.Results: Advice to reviewers is on the whole consistent and sensible. However, examination of a sample of Cochrane protocols and reviews demonstrates that the advice is difficult to follow given the small numbers of studies identified in many systematic reviews, the difficulty of pre-specifying important effect modifiers for subgroup analysis or meta-regression and the unresolved debate concerning fixed versus random effects metaanalyses. There was disagreement between protocols and reviews, often either regarding choice of important potential effect modifiers or due to the review identifying too few studies to perform planned analyses.Conclusion: Guidelines that address practical issues are required to reduce the risk of spurious findings from investigations of heterogeneity. This may involve discouraging statistical investigations such as subgroup analyses and meta-regression, rather than simply adopting a cautious approach to their interpretation, unless a large number of studies is available. The notion of a priori specification of potential effect modifiers for a retrospective review of studies is ill-defined, and the appropriateness of using a statistical test for heterogeneity to decide between analysis strategies is suspect.},
  langid = {english}
}

@article{hoijtinkTutorialTestingHypotheses2019,
  title = {A Tutorial on Testing Hypotheses Using the {{Bayes}} Factor},
  author = {Hoijtink, Herbert and Mulder, Joris and family=Lissa, given=Caspar, prefix=van, useprefix=true and Gu, Xin},
  date = {2019},
  journaltitle = {Psychological Methods},
  volume = {24},
  number = {5},
  pages = {539--556},
  issn = {1939-1463(Electronic),1082-989X(Print)},
  doi = {10.1037/met0000201},
  abstract = {Learning about hypothesis evaluation using the Bayes factor could enhance psychological research. In contrast to null-hypothesis significance testing it renders the evidence in favor of each of the hypotheses under consideration (it can be used to quantify support for the null-hypothesis) instead of a dichotomous reject/do-not-reject decision; it can straightforwardly be used for the evaluation of multiple hypotheses without having to bother about the proper manner to account for multiple testing; and it allows continuous reevaluation of hypotheses after additional data have been collected (Bayesian updating). This tutorial addresses researchers considering to evaluate their hypotheses by means of the Bayes factor. The focus is completely applied and each topic discussed is illustrated using Bayes factors for the evaluation of hypotheses in the context of an ANOVA model, obtained using the R package bain. Readers can execute all the analyses presented while reading this tutorial if they download bain and the R-codes used. It will be elaborated in a completely nontechnical manner: what the Bayes factor is, how it can be obtained, how Bayes factors should be interpreted, and what can be done with Bayes factors. After reading this tutorial and executing the associated code, researchers will be able to use their own data for the evaluation of hypotheses by means of the Bayes factor, not only in the context of ANOVA models, but also in the context of other statistical models. (PsycINFO Database Record (c) 2019 APA, all rights reserved)},
  keywords = {Analysis of Variance,Errors,Hypothesis Testing,Null Hypothesis Testing,Statistical Probability,Statistical Significance},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\DNQD4RXS\\Hoijtink et al_2019_A tutorial on testing hypotheses using the Bayes factor.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\8UP5I6ZT\\2019-07157-001.html}
}

@book{schwarzerMetaAnalysis2015,
  title = {Meta-{{Analysis}} with {{R}}},
  author = {Schwarzer, Guido and Carpenter, James R. and Rücker, Gerta},
  date = {2015},
  series = {Use {{R}}!},
  publisher = {Springer International Publishing},
  location = {Cham},
  doi = {10.1007/978-3-319-21416-0},
  url = {https://link.springer.com/10.1007/978-3-319-21416-0},
  urldate = {2024-10-16},
  isbn = {978-3-319-21415-3 978-3-319-21416-0},
  langid = {english},
  keywords = {diagnostic studies,meta-analysis,missing data,multivariate analysis,small study effects}
}

@report{vanlissaAggregatingEvidenceConceptual2023,
  type = {preprint},
  title = {Aggregating Evidence from Conceptual Replication Studies Using the Product {{Bayes}} Factor},
  author = {Van Lissa, Caspar J. and Kuiper, Rebecca M. and Clapper, Eli-Boaz},
  date = {2023-04-25},
  institution = {PsyArXiv},
  doi = {10.31234/osf.io/nvqpw},
  url = {https://osf.io/nvqpw},
  urldate = {2024-01-31},
  abstract = {The product Bayes factor (PBF) can synthesize evidence for an informative hypothesis across heterogeneous replication studies. It is particularly useful when the number of studies is relatively low and conventional assumptions about between-studies heterogeneity are likely violated. The present paper introduces a user-friendly implementation of the PBF in the bain R-package. The method was validated in a simulation study that manipulated sample size, number of replication samples, and reliability. Several tutorial examples demonstrate the use of the method in distinct use cases. Results of the simulation study show that PBF had a higher overall accuracy when benchmarked against other evidence synthesis methods, including random-effects meta-analysis (RMA). This was primarily due to PBF’s greater sensitivity in detecting a true effect. However, PBF had relatively lower specificity. The PBF showed increasing sensitivity and specificity with increasing sample size. With an increasing number of samples, lower sensitivity was traded for greater specificity. Although PBF's overall performance was less susceptible to reliability than the other algorithms, this masked a trade-off between reliability and specificity. PBF thus appears to be a promising method for meta-analysis of heterogeneous conceptual replication studies. Nonetheless, users should be aware of its lower specificity, and the fact that the Bayesian approach to inference addresses a qualitatively different research question than other evidence synthesis methods.},
  langid = {english}
}

@article{vanlissaSelectingRelevantModerators2023a,
  title = {Selecting Relevant Moderators with {{Bayesian}} Regularized Meta-Regression},
  author = {Van Lissa, Caspar J. and family=Erp, given=Sara, prefix=van, useprefix=true and Clapper, Eli-Boaz},
  date = {2023},
  journaltitle = {Research Synthesis Methods},
  volume = {14},
  number = {2},
  pages = {301--322},
  issn = {1759-2887},
  doi = {10.1002/jrsm.1628},
  url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/jrsm.1628},
  urldate = {2024-01-31},
  abstract = {When meta-analyzing heterogeneous bodies of literature, meta-regression can be used to account for potentially relevant between-studies differences. A key challenge is that the number of candidate moderators is often high relative to the number of studies. This introduces risks of overfitting, spurious results, and model non-convergence. To overcome these challenges, we introduce Bayesian Regularized Meta-Analysis (BRMA), which selects relevant moderators from a larger set of candidates by shrinking small regression coefficients towards zero with regularizing (LASSO or horseshoe) priors. This method is suitable when there are many potential moderators, but it is not known beforehand which of them are relevant. A simulation study compared BRMA against state-of-the-art random effects meta-regression using restricted maximum likelihood (RMA). Results indicated that BRMA outperformed RMA on three metrics: BRMA had superior predictive performance, which means that the results generalized better; BRMA was better at rejecting irrelevant moderators, and worse at detecting true effects of relevant moderators, while the overall proportion of Type I and Type II errors was equivalent to RMA. BRMA regression coefficients were slightly biased towards zero (by design), but its residual heterogeneity estimates were less biased than those of RMA. BRMA performed well with as few as 20 studies, suggesting its suitability as a small sample solution. We present free open source software implementations in the R-package pema (for penalized meta-analysis) and in the stand-alone statistical program JASP. An applied example demonstrates the use of the R-package.},
  langid = {english},
  keywords = {bayesian,horseshoe,lasso,machine learning,meta-analysis,regularization},
  file = {C\:\\Users\\vanlissa\\Zotero\\storage\\J44PZV55\\Van Lissa et al. - 2023 - Selecting relevant moderators with Bayesian regula.pdf;C\:\\Users\\vanlissa\\Zotero\\storage\\EG5SS99B\\jrsm.html}
}

@incollection{vanlissaSmallSampleMetaanalyses2020,
  title = {Small Sample Meta-Analyses: {{Exploring}} Heterogeneity Using {{MetaForest}}},
  shorttitle = {Small {{Sample Size Solutions}} ({{Open Access}})},
  booktitle = {Small {{Sample Size Solutions}} ({{Open Access}}): {{A Guide}} for {{Applied Researchers}} and {{Practitioners}}},
  author = {Van Lissa, Caspar J.},
  editor = {Van De Schoot, Rens and Miočević, Milica},
  date = {2020},
  series = {European {{Association}} of {{Methodology Series}}},
  publisher = {CRC Press},
  abstract = {This unique resource provides guidelines and tools for implementing solutions to issues that arise in small sample research, illustrating statistical methods that allow researchers to apply the optimal statistical model for their research question when the sample is too small. Researchers often have},
  isbn = {978-0-367-22222-2},
  langid = {english},
  file = {C:\Users\vanlissa\Zotero\storage\AUYGHXGC\9780367222222.html}
}

@article{vanlissaTeacherCornerEvaluating2020,
  title = {Teacher’s {{Corner}}: {{Evaluating Informative Hypotheses Using}} the {{Bayes Factor}} in {{Structural Equation Models}}},
  shorttitle = {Teacher’s {{Corner}}},
  author = {Van Lissa, Caspar J. and Gu, Xin and Mulder, Joris and Rosseel, Yves and Zundert, Camiel Van and Hoijtink, Herbert},
  date = {2020-05-29},
  journaltitle = {Structural Equation Modeling: A Multidisciplinary Journal},
  volume = {0},
  number = {0},
  pages = {1--10},
  publisher = {Routledge},
  issn = {1070-5511},
  doi = {10.1080/10705511.2020.1745644},
  url = {https://doi.org/10.1080/10705511.2020.1745644},
  urldate = {2020-08-18},
  abstract = {This Teacher’s Corner paper introduces Bayesian evaluation of informative hypotheses for structural equation models, using the free open-source R packages bain, for Bayesian informative hypothesis testing, and lavaan, a widely used SEM package. The introduction provides a brief non-technical explanation of informative hypotheses, the statistical underpinnings of Bayesian hypothesis evaluation, and the bain algorithm. Three tutorial examples demonstrate informative hypothesis evaluation in the context of common types of structural equation models: 1) confirmatory factor analysis, 2) latent variable regression, and 3) multiple group analysis. We discuss hypothesis formulation, the interpretation of Bayes factors and posterior model probabilities, and sensitivity analysis.},
  keywords = {Bain,bayes factor,informative hypotheses,structural equation modeling}
}

@article{viechtbauerConductingMetaanalysesMetafor2010,
  title = {Conducting Meta-Analyses in {{R}} with the Metafor Package},
  author = {Viechtbauer, Wolfgang},
  date = {2010},
  journaltitle = {Journal of Statistical Software},
  volume = {36},
  number = {3},
  pages = {1--48},
  url = {http://www.jstatsoft.org/v36/i03/},
  file = {C:\Users\vanlissa\Zotero\storage\SKIFUP3J\Viechtbauer_others_2010_Conducting meta-analyses in R with the metafor package.pdf}
}
