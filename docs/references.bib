
@article{stekhovenMissForestNonparametricMissing2012,
  title = {{{MissForest}}\textemdash{}Non-Parametric Missing Value Imputation for Mixed-Type Data},
  volume = {28},
  issn = {1367-4803, 1460-2059},
  abstract = {Motivation: Modern data acquisition based on high-throughput technology is often facing the problem of missing data. Algorithms commonly used in the analysis of such large-scale data often depend on a complete set. Missing value imputation offers a solution to this problem. However, the majority of available imputation methods are restricted to one type of variable only: continuous or categorical. For mixed-type data, the different types are usually handled separately. Therefore, these methods ignore possible relations between variable types. We propose a non-parametric method which can cope with different types of variables simultaneously.
Results: We compare several state of the art methods for the imputation of missing values. We propose and evaluate an iterative imputation method (missForest) based on a random forest. By averaging over many unpruned classification or regression trees, random forest intrinsically constitutes a multiple imputation scheme. Using the built-in out-of-bag error estimates of random forest, we are able to estimate the imputation error without the need of a test set. Evaluation is performed on multiple datasets coming from a diverse selection of biological fields with artificially introduced missing values ranging from 10\% to 30\%. We show that missForest can successfully handle missing values, particularly in datasets including different types of variables. In our comparative study, missForest outperforms other methods of imputation especially in data settings where complex interactions and non-linear relations are suspected. The out-of-bag imputation error estimates of missForest prove to be adequate in all settings. Additionally, missForest exhibits attractive computational efficiency and can cope with high-dimensional data.
Availability: The {$\mathbb{R}$} package missForest is freely available from http://stat.ethz.ch/CRAN/.
Contact: stekhoven@stat.math.ethz.ch; buhlmann@stat.math.ethz.ch},
  language = {en},
  number = {1},
  journal = {Bioinformatics},
  doi = {10.1093/bioinformatics/btr597},
  author = {Stekhoven, Daniel J. and B{\"u}hlmann, Peter},
  month = jan,
  year = {2012},
  pages = {112-118},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GG7FDGVE\\Stekhoven_Bühlmann_2012_MissForest—non-parametric missing value imputation for mixed-type data.pdf;C:\\Users\\lissa102\\Zotero\\storage\\TMVUVEUJ\\Stekhoven and Bühlmann - 2012 - MissForest—non-parametric missing value imputation.pdf;C:\\Users\\lissa102\\Zotero\\storage\\JKF5BDR5\\112.html;C:\\Users\\lissa102\\Zotero\\storage\\XAUSP58G\\Stekhoven and Bühlmann - 2012 - MissForest—non-parametric missing value imputation.html},
  pmid = {22039212}
}

@article{dusseldorpCombinationsTechniquesThat2014,
  title = {Combinations of Techniques That Effectively Change Health Behavior: {{Evidence}} from {{Meta}}-{{CART}} Analysis.},
  volume = {33},
  issn = {1930-7810, 0278-6133},
  shorttitle = {Combinations of Techniques That Effectively Change Health Behavior},
  language = {en},
  number = {12},
  journal = {Health Psychology},
  doi = {10.1037/hea0000018},
  author = {Dusseldorp, Elise and {van Genugten}, Lenneke and {van Buuren}, Stef and Verheijden, Marieke W. and {van Empelen}, Pepijn},
  year = {2014},
  pages = {1530-1540},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\H3M8VK64\\Dusseldorp et al. - 2014 - Combinations of techniques that effectively change.pdf}
}

@article{janitzaComputationallyFastVariable2016,
  title = {A Computationally Fast Variable Importance Test for Random Forests for High-Dimensional Data},
  issn = {1862-5347, 1862-5355},
  abstract = {Random forests are a commonly used tool for classification and for ranking candidate predictors based on the so-called variable importance measures. These measures attribute scores to the variables reflecting their importance. A drawback of variable importance measures is that there is no natural cutoff that can be used to discriminate between important and non-important variables. Several approaches, for example approaches based on hypothesis testing, were developed for addressing this problem. The existing testing approaches require the repeated computation of random forests. While for low-dimensional settings those approaches might be computationally tractable, for high-dimensional settings typically including thousands of candidate predictors, computing time is enormous. In this article a computationally fast heuristic variable importance test is proposed that is appropriate for high-dimensional data where many variables do not carry any information. The testing approach is based on a modified version of the permutation variable importance, which is inspired by cross-validation procedures. The new approach is tested and compared to the approach of Altmann and colleagues using simulation studies, which are based on real data from high-dimensional binary classification settings. The new approach controls the type I error and has at least comparable power at a substantially smaller computation time in the studies. Thus, it might be used as a computationally fast alternative to existing procedures for high-dimensional data settings where many variables do not carry any information. The new approach is implemented in the R package vita.},
  language = {en},
  journal = {Advances in Data Analysis and Classification},
  doi = {10.1007/s11634-016-0270-x},
  author = {Janitza, Silke and Celik, Ender and Boulesteix, Anne-Laure},
  month = sep,
  year = {2016},
  pages = {1-31},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\6JDDXAVM\\Janitza et al_2016_A computationally fast variable importance test for random forests for.pdf;C:\\Users\\lissa102\\Zotero\\storage\\N7V44B7Q\\s11634-016-0270-x.html}
}

@article{boulesteixEvaluatingMicroarraybasedClassifiers2008,
  title = {Evaluating {{Microarray}}-Based {{Classifiers}}: {{An Overview}}},
  volume = {6},
  issn = {1176-9351},
  shorttitle = {Evaluating {{Microarray}}-Based {{Classifiers}}},
  abstract = {For the last eight years, microarray-based class prediction has been the subject of numerous publications in medicine, bioinformatics and statistics journals. However, in many articles, the assessment of classification accuracy is carried out using suboptimal procedures and is not paid much attention. In this paper, we carefully review various statistical aspects of classifier evaluation and validation from a practical point of view. The main topics addressed are accuracy measures, error rate estimation procedures, variable selection, choice of classifiers and validation strategy.},
  journal = {Cancer Informatics},
  author = {Boulesteix, A.-L. and Strobl, C. and Augustin, T. and Daumer, M.},
  month = feb,
  year = {2008},
  pages = {77-97},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\R7DRFBIU\\Boulesteix et al_2008_Evaluating Microarray-based Classifiers.pdf},
  pmid = {19259405},
  pmcid = {PMC2623308}
}

@book{borensteinIntroductionMetaAnalysis2009,
  title = {Introduction to {{Meta}}-{{Analysis}}},
  copyright = {Copyright \textcopyright{} 2009 John Wiley \& Sons, Ltd},
  isbn = {978-0-470-74338-6},
  language = {en},
  publisher = {{John Wiley \& Sons, Ltd}},
  author = {Borenstein, Michael and Hedges, Larry V. and Higgins, Julian P. T. and Rothstein, Hannah R.},
  year = {2009},
  keywords = {meta-analysis,Meta-Analysis as Topic},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\8U6XAR8B\\Borenstein - Introduction to Meta-analysis.pdf;C:\\Users\\lissa102\\Zotero\\storage\\R975CG6N\\summary.html},
  doi = {10.1002/9780470743386}
}

@article{prasadNewerClassificationRegression2006,
  title = {Newer {{Classification}} and {{Regression Tree Techniques}}: {{Bagging}} and {{Random Forests}} for {{Ecological Prediction}}},
  volume = {9},
  issn = {1432-9840, 1435-0629},
  shorttitle = {Newer {{Classification}} and {{Regression Tree Techniques}}},
  language = {en},
  number = {2},
  journal = {Ecosystems},
  doi = {10.1007/s10021-005-0054-1},
  author = {Prasad, Anantha M. and Iverson, Louis R. and Liaw, Andy},
  month = mar,
  year = {2006},
  pages = {181-199},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\8VVIC5TB\\Newer_Classification_and_Regression_Tree20160616-6828-2h04a4.pdf}
}

@article{wagenmakers_power_2015,
  title = {A Power Fallacy},
  volume = {47},
  issn = {1554-3528},
  abstract = {The power fallacy refers to the misconception that what holds on average -across an ensemble of hypothetical experiments- also holds for each case individually. According to the fallacy, high-power experiments always yield more informative data than do low-power experiments. Here we expose the fallacy with concrete examples, demonstrating that a particular outcome from a high-power experiment can be completely uninformative, whereas a particular outcome from a low-power experiment can be highly informative. Although power is useful in planning an experiment, it is less useful-and sometimes even misleading-for making inferences from observed data. To make inferences from data, we recommend the use of likelihood ratios or Bayes factors, which are the extension of likelihood ratios beyond point hypotheses. These methods of inference do not average over hypothetical replications of an experiment, but instead condition on the data that have actually been observed. In this way, likelihood ratios and Bayes factors rationally quantify the evidence that a particular data set provides for or against the null or any other hypothesis.},
  language = {eng},
  number = {4},
  journal = {Behavior Research Methods},
  doi = {10.3758/s13428-014-0517-4},
  author = {Wagenmakers, Eric-Jan and Verhagen, Josine and Ly, Alexander and Bakker, Marjan and Lee, Michael D. and Matzke, Dora and Rouder, Jeffrey N. and Morey, Richard D.},
  month = dec,
  year = {2015},
  keywords = {Statistics as Topic,humans,Bayes factor,Bayes Theorem,Hypothesis test,Likelihood ratio,Sample size,Statistical evidence},
  pages = {913-917},
  pmid = {25271090}
}

@incollection{suttonClassificationRegressionTrees2005,
  title = {Classification and {{Regression Trees}}, {{Bagging}}, and {{Boosting}}},
  volume = {24},
  isbn = {978-0-444-51141-6},
  language = {en},
  booktitle = {Handbook of {{Statistics}}},
  publisher = {{Elsevier}},
  author = {Sutton, Clifton D.},
  year = {2005},
  pages = {303-329},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\PKZAMBRJ\\Sutton_2005_Classification and Regression Trees, Bagging, and Boosting.pdf},
  doi = {10.1016/S0169-7161(04)24011-1}
}

@article{huedo-medinaAssessingHeterogeneityMetaanalysis2006,
  title = {Assessing Heterogeneity in Meta-Analysis: {{Q}} Statistic or {{I}}{$^2$} Index?},
  volume = {11},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  shorttitle = {Assessing Heterogeneity in Meta-Analysis},
  abstract = {In meta-analysis, the usual way of assessing whether a set of single studies is homogeneous is by means of the Q test. However, the Q test only informs meta-analysts about the presence versus the absence of heterogeneity, but it does not report on the extent of such heterogeneity. Recently, the I{$^2$} index has been proposed to quantify the degree of heterogeneity in a meta-analysis. In this article, the performances of the Q test and the confidence interval around the I{$^2$} index are compared by means of a Monte Carlo simulation. The results show the utility of the I{$^2$} index as a complement to the Q test, although it has the same problems of power with a small number of studies.},
  language = {English},
  number = {2},
  journal = {Psychological Methods},
  doi = {10.1037/1082-989X.11.2.193},
  author = {{Huedo-Medina}, Tania B. and {S{\'a}nchez-Meca}, Julio and {Mar{\'i}n-Mart{\'i}nez}, Fulgencio and Botella, Juan},
  year = {2006},
  keywords = {*Meta Analysis,*Homogeneity of Variance,*Statistical Tests,Nonparametric Statistical Tests,Simulation},
  pages = {193-206},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\3T6MF2U4\\Huedo-Medina et al_2006_Assessing heterogeneity in meta-analysis.pdf}
}

@article{brandmaierStructuralEquationModel2013,
  title = {Structural Equation Model Trees},
  volume = {18},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  abstract = {In the behavioral and social sciences, structural equation models (SEMs) have become widely accepted as a modeling tool for the relation between latent and observed variables. SEMs can be seen as a unification of several multivariate analysis techniques. SEM Trees combine the strengths of SEMs and the decision tree paradigm by building tree structures that separate a data set recursively into subsets with significantly different parameter estimates in a SEM. SEM Trees provide means for finding covariates and covariate interactions that predict differences in structural parameters in observed as well as in latent space and facilitate theory-guided exploration of empirical data. We describe the methodology, discuss theoretical and practical implications, and demonstrate applications to a factor model and a linear growth curve model.},
  language = {English},
  number = {1},
  journal = {Psychological Methods},
  doi = {10.1037/a0030001},
  author = {Brandmaier, Andreas M. and {von Oertzen}, Timo and McArdle, John J. and Lindenberger, Ulman},
  year = {2013},
  keywords = {*Structural Equation Modeling,Data Mining},
  pages = {71-86},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\TA2JWCJ6\\Brandmaier et al_2013_Structural equation model trees.pdf}
}

@article{liMetaanalysisBasedVariable2014,
  title = {Meta-Analysis Based Variable Selection for Gene Expression Data},
  volume = {70},
  issn = {1541-0420},
  abstract = {Recent advance in biotechnology and its wide applications have led to the generation of many high-dimensional gene expression data sets that can be used to address similar biological questions. Meta-analysis plays an important role in summarizing and synthesizing scientific evidence from multiple studies. When the dimensions of datasets are high, it is desirable to incorporate variable selection into meta-analysis to improve model interpretation and prediction. According to our knowledge, all existing methods conduct variable selection with meta-analyzed data in an "all-in-or-all-out" fashion, that is, a gene is either selected in all of studies or not selected in any study. However, due to data heterogeneity commonly exist in meta-analyzed data, including choices of biospecimens, study population, and measurement sensitivity, it is possible that a gene is important in some studies while unimportant in others. In this article, we propose a novel method called meta-lasso for variable selection with high-dimensional meta-analyzed data. Through a hierarchical decomposition on regression coefficients, our method not only borrows strength across multiple data sets to boost the power to identify important genes, but also keeps the selection flexibility among data sets to take into account data heterogeneity. We show that our method possesses the gene selection consistency, that is, when sample size of each data set is large, with high probability, our method can identify all important genes and remove all unimportant genes. Simulation studies demonstrate a good performance of our method. We applied our meta-lasso method to a meta-analysis of five cardiovascular studies. The analysis results are clinically meaningful.},
  language = {eng},
  number = {4},
  journal = {Biometrics},
  doi = {10.1111/biom.12213},
  author = {Li, Quefeng and Wang, Sijian and Huang, Chiang-Ching and Yu, Menggang and Shao, Jun},
  month = dec,
  year = {2014},
  keywords = {meta-analysis,Computer Simulation,Algorithms,Meta-Analysis as Topic,Sample size,Data Interpretation; Statistical,Gene Expression Profiling,Gene selection,High dimension,Models; Statistical,Weak oracle property},
  pages = {872-880},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\W3Q6XBP8\\Li et al_2014_Meta-analysis based variable selection for gene expression data.pdf},
  pmid = {25196635}
}

@article{higginsReevaluationRandomeffectsMetaanalysis2009,
  title = {A Re-Evaluation of Random-Effects Meta-Analysis},
  volume = {172},
  issn = {0964-1998},
  abstract = {Meta-analysis in the presence of unexplained heterogeneity is frequently undertaken by using a random-effects model, in which the effects underlying different studies are assumed to be drawn from a normal distribution. Here we discuss the justification and interpretation of such models, by addressing in turn the aims of estimation, prediction and hypothesis testing. A particular issue that we consider is the distinction between inference on the mean of the random-effects distribution and inference on the whole distribution. We suggest that random-effects meta-analyses as currently conducted often fail to provide the key results, and we investigate the extent to which distribution-free, classical and Bayesian approaches can provide satisfactory methods. We conclude that the Bayesian approach has the advantage of naturally allowing for full uncertainty, especially for prediction. However, it is not without problems, including computational intensity and sensitivity to a priori judgements. We propose a simple prediction interval for classical meta-analysis and offer extensions to standard practice of Bayesian meta-analysis, making use of an example of studies of `set shifting' ability in people with eating disorders.},
  number = {1},
  journal = {Journal of the Royal Statistical Society. Series A, (Statistics in Society)},
  doi = {10.1111/j.1467-985X.2008.00552.x},
  author = {Higgins, Julian P T and Thompson, Simon G and Spiegelhalter, David J},
  month = jan,
  year = {2009},
  pages = {137-159},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\9RPWEBFF\\Higgins et al. - 2009 - A re-evaluation of random-effects meta-analysis.pdf},
  pmid = {19381330},
  pmcid = {PMC2667312}
}

@article{hedgesPowerStatisticalTests2004,
  title = {The {{Power}} of {{Statistical Tests}} for {{Moderators}} in {{Meta}}-{{Analysis}}.},
  volume = {9},
  issn = {1939-1463, 1082-989X},
  language = {en},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/1082-989X.9.4.426},
  author = {Hedges, Larry V. and Pigott, Therese D.},
  year = {2004},
  pages = {426-445},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\RP5F6M2W\\Hedges_Pigott_2004_The Power of Statistical Tests for Moderators in Meta-Analysis.pdf}
}

@article{weltonMixedTreatmentComparison2009,
  title = {Mixed {{Treatment Comparison Meta}}-{{Analysis}} of {{Complex Interventions}}: {{Psychological Interventions}} in {{Coronary Heart Disease}}},
  volume = {169},
  issn = {0002-9262},
  shorttitle = {Mixed {{Treatment Comparison Meta}}-{{Analysis}} of {{Complex Interventions}}},
  number = {9},
  journal = {American Journal of Epidemiology},
  doi = {10.1093/aje/kwp014},
  author = {Welton, Nicky J. and Caldwell, D. M. and Adamopoulos, E. and Vedhara, K.},
  month = may,
  year = {2009},
  pages = {1158-1165},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\T62WAAA3\\Welton et al_2009_Mixed Treatment Comparison Meta-Analysis of Complex Interventions.pdf;C:\\Users\\lissa102\\Zotero\\storage\\7HBBUP97\\Mixed-Treatment-Comparison-Meta-Analysis-of.html}
}

@article{aguinisBestpracticeRecommendationsEstimating2011,
  title = {Best-Practice Recommendations for Estimating Interaction Effects Using Meta-Analysis},
  volume = {32},
  issn = {08943796},
  language = {en},
  number = {8},
  journal = {Journal of Organizational Behavior},
  doi = {10.1002/job.719},
  author = {Aguinis, Herman and Gottfredson, Ryan K. and Wright, Thomas A.},
  month = nov,
  year = {2011},
  pages = {1033-1043},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\29IRN3FA\\Aguinis et al_2011_Best-practice recommendations for estimating interaction effects using.pdf}
}

@article{overtonComparisonFixedeffectsMixed1998,
  title = {A Comparison of Fixed-Effects and Mixed (Random-Effects) Models for Meta-Analysis Tests of Moderator Variable Effects},
  volume = {3},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  abstract = {The growing popularity of meta-analysis has focused increased attention on the statistical models analysts are using and the assumptions underlying these models. Although comparisons often have been limited to fixed-effects (FE) models, recently there has been a call to investigate the differences between FE and random-effects (RE) models, differences that may have substantial theoretical and applied implications (National Research Council, 1992). Three FE models (including L. V. Hedges \& I. Olkin's, 1985, and R. Rosenthal's, 1991, tests) and 2 RE models were applied to simulated correlation data in tests for moderator effects. The FE models seriously underestimated and the RE models greatly overestimated sampling error variance when their basic assumptions were violated, which caused biased confidence intervals and hypothesis tests. The implications of these and other findings are discussed as are methodological issues concerning meta-analyses.},
  number = {3},
  journal = {Psychological Methods},
  doi = {10.1037/1082-989X.3.3.354},
  author = {Overton, Randall C.},
  year = {1998},
  keywords = {*Mathematical Modeling,*Statistical Analysis,*Meta Analysis,*Effect Size (Statistical),*Statistical Variables,Statistical Tests},
  pages = {354-379},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\CN8ANUGX\\index.html}
}

@article{higginsQuantifyingHeterogeneityMetaanalysis2002,
  title = {Quantifying Heterogeneity in a Meta-Analysis},
  volume = {21},
  issn = {1097-0258},
  abstract = {The extent of heterogeneity in a meta-analysis partly determines the difficulty in drawing overall conclusions. This extent may be measured by estimating a between-study variance, but interpretation is then specific to a particular treatment effect metric. A test for the existence of heterogeneity exists, but depends on the number of studies in the meta-analysis. We develop measures of the impact of heterogeneity on a meta-analysis, from mathematical criteria, that are independent of the number of studies and the treatment effect metric. We derive and propose three suitable statistics: H is the square root of the {$\chi$}2 heterogeneity statistic divided by its degrees of freedom; R is the ratio of the standard error of the underlying mean from a random effects meta-analysis to the standard error of a fixed effect meta-analytic estimate, and I2 is a transformation of H that describes the proportion of total variation in study estimates that is due to heterogeneity. We discuss interpretation, interval estimates and other properties of these measures and examine them in five example data sets showing different amounts of heterogeneity. We conclude that H and I2, which can usually be calculated for published meta-analyses, are particularly useful summaries of the impact of heterogeneity. One or both should be presented in published meta-analyses in preference to the test for heterogeneity. Copyright \textcopyright{} 2002 John Wiley \& Sons, Ltd.},
  language = {en},
  number = {11},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.1186},
  author = {Higgins, Julian P. T. and Thompson, Simon G.},
  month = jun,
  year = {2002},
  keywords = {meta-analysis,heterogeneity},
  pages = {1539-1558},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\36Z6KQKW\\Higgins_Thompson_2002_Quantifying heterogeneity in a meta-analysis.pdf;C:\\Users\\lissa102\\Zotero\\storage\\H4HCPEFB\\abstract.html}
}

@article{brockwellComparisonStatisticalMethods2001,
  title = {A Comparison of Statistical Methods for Meta-Analysis},
  volume = {20},
  issn = {1097-0258},
  abstract = {Meta-analysis may be used to estimate an overall effect across a number of similar studies. A number of statistical techniques are currently used to combine individual study results. The simplest of these is based on a fixed effects model, which assumes the true effect is the same for all studies. A random effects model, however, allows the true effect to vary across studies, with the mean true effect the parameter of interest. We consider three methods currently used for estimation within the framework of a random effects model, and illustrate them by applying each method to a collection of six studies on the effect of aspirin after myocardial infarction. These methods are compared using estimated coverage probabilities of confidence intervals for the overall effect. The techniques considered all generally have coverages below the nominal level, and in particular it is shown that the commonly used DerSimonian and Laird method does not adequately reflect the error associated with parameter estimation, especially when the number of studies is small. Copyright \textcopyright{} 2001 John Wiley \& Sons, Ltd.},
  language = {en},
  number = {6},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.650},
  author = {Brockwell, Sarah E. and Gordon, Ian R.},
  month = mar,
  year = {2001},
  pages = {825-840},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\U5HL9S5G\\Brockwell and Gordon - 2001 - A comparison of statistical methods for meta-analy.pdf;C:\\Users\\lissa102\\Zotero\\storage\\MJFZMFQR\\abstract.html}
}

@article{guoloRandomeffectsMetaanalysisNumber2015,
  title = {Random-Effects Meta-Analysis: The Number of Studies Matters},
  issn = {0962-2802},
  shorttitle = {Random-Effects Meta-Analysis},
  abstract = {This paper investigates the impact of the number of studies on meta-analysis and meta-regression within the random-effects model framework. It is frequently neglected that inference in random-effects models requires a substantial number of studies included in meta-analysis to guarantee reliable conclusions. Several authors warn about the risk of inaccurate results of the traditional DerSimonian and Laird approach especially in the common case of meta-analysis involving a limited number of studies. This paper presents a selection of likelihood and non-likelihood methods for inference in meta-analysis proposed to overcome the limitations of the DerSimonian and Laird procedure, with a focus on the effect of the number of studies. The applicability and the performance of the methods are investigated in terms of Type I error rates and empirical power to detect effects, according to scenarios of practical interest. Simulation studies and applications to real meta-analyses highlight that it is not possible to identify an approach uniformly superior to alternatives. The overall recommendation is to avoid the DerSimonian and Laird method when the number of meta-analysis studies is modest and prefer a more comprehensive procedure that compares alternative inferential approaches. R code for meta-analysis according to all of the inferential methods examined in the paper is provided.},
  language = {en},
  journal = {Statistical Methods in Medical Research},
  doi = {10.1177/0962280215583568},
  author = {Guolo, Annamaria and Varin, Cristiano},
  month = may,
  year = {2015},
  pages = {0962280215583568},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\PSWBSIZU\\Guolo_Varin_2015_Random-effects meta-analysis.pdf}
}

@article{landersPrimerTheorydrivenWeb2016,
  title = {A Primer on Theory-Driven Web Scraping: {{Automatic}} Extraction of Big Data from the {{Internet}} for Use in Psychological Research},
  volume = {21},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  shorttitle = {A Primer on Theory-Driven Web Scraping},
  abstract = {The term big data encompasses a wide range of approaches of collecting and analyzing data in ways that were not possible before the era of modern personal computing. One approach to big data of great potential to psychologists is web scraping, which involves the automated collection of information from webpages. Although web scraping can create massive big datasets with tens of thousands of variables, it can also be used to create modestly sized, more manageable datasets with tens of variables but hundreds of thousands of cases, well within the skillset of most psychologists to analyze, in a matter of hours. In this article, we demystify web scraping methods as currently used to examine research questions of interest to psychologists. First, we introduce an approach called theory-driven web scraping in which the choice to use web-based big data must follow substantive theory. Second, we introduce data source theories, a term used to describe the assumptions a researcher must make about a prospective big data source in order to meaningfully scrape data from it. Critically, researchers must derive specific hypotheses to be tested based upon their data source theory, and if these hypotheses are not empirically supported, plans to use that data source should be changed or eliminated. Third, we provide a case study and sample code in Python demonstrating how web scraping can be conducted to collect big data along with links to a web tutorial designed for psychologists. Fourth, we describe a 4-step process to be followed in web scraping projects. Fifth and finally, we discuss legal, practical and ethical concerns faced when conducting web scraping projects.},
  language = {English},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/met0000081},
  author = {Landers, Richard N. and Brusso, Robert C. and Cavanaugh, Katelyn J. and Collmus, Andrew B.},
  year = {2016},
  keywords = {*Theories,*Data Sets,*Experimentation,*Internet,*Psychology,Websites},
  pages = {475-492}
}

@book{trikalinosMethods2013,
  title = {Methods},
  abstract = {Figure 1 outlines our simulation approach. Briefly, we generated 792 distinct scenarios for meta-analyses of proportions, and 792 scenarios for meta-analyses of incidence rates. These are formed by all possible combinations of choices for the parameters of our generative model.},
  language = {en},
  publisher = {{Agency for Healthcare Research and Quality (US)}},
  author = {Trikalinos, Thomas A. and Trow, Paul and Schmid, Christopher H.},
  month = nov,
  year = {2013},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\XK7K5R5Q\\NBK179163.html}
}

@phdthesis{martinEfficientlyExploringMultilevel2015,
  title = {Efficiently Exploring Multilevel Data with Recursive Partitioning},
  school = {University of Virginia},
  author = {Martin, Daniel Patrick},
  year = {2015},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GZ36RKVI\\Martin_2015_Efficiently exploring multilevel data with recursive partitioning.pdf}
}

@misc{MetaanalysisThereWay,
  title = {Meta-Analysis: Is There a Way of Including Dependent Effect Sizes without Averaging across Them - {{Cross Validated}}},
  shorttitle = {Meta-Analysis},
  howpublished = {https://stats.stackexchange.com/questions/151157/meta-analysis-is-there-a-way-of-including-dependent-effect-sizes-without-averag},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\6U4X9SR7\\meta-analysis-is-there-a-way-of-including-dependent-effect-sizes-without-averag.html}
}

@article{beckerSynthesisRegressionSlopes2007,
  title = {The {{Synthesis}} of {{Regression Slopes}} in {{Meta}}-{{Analysis}}},
  volume = {22},
  issn = {0883-4237},
  language = {en},
  number = {3},
  journal = {Statistical Science},
  doi = {10.1214/07-STS243},
  author = {Becker, Betsy Jane and Wu, Meng-Jia},
  month = aug,
  year = {2007},
  pages = {414-429},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\EH4MW2N6\\Becker_Wu_2007_The Synthesis of Regression Slopes in Meta-Analysis.pdf}
}

@article{petersonUseBetaCoefficients2005,
  title = {On the {{Use}} of {{Beta Coefficients}} in {{Meta}}-{{Analysis}}.},
  volume = {90},
  issn = {0021-9010},
  language = {en},
  number = {1},
  journal = {Journal of Applied Psychology},
  doi = {10.1037/0021-9010.90.1.175},
  author = {Peterson, Robert A. and Brown, Steven P.},
  year = {2005},
  pages = {175-181},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\525NEUDU\\Peterson_Brown_2005_On the Use of Beta Coefficients in Meta-Analysis.pdf}
}

@misc{AreThereAny,
  title = {Are There Any Plans for a Partial Dependency Plot {$\cdot$} {{Issue}} \#122 {$\cdot$} Imbs-Hl/Ranger},
  abstract = {as in randomForest:::partialPlot.randomForest
or as in randomForestSRC::plot.variable},
  journal = {GitHub},
  howpublished = {https://github.com/imbs-hl/ranger/issues/122},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\7RGXUM4R\\122.html}
}

@article{altmannPermutationImportanceCorrected2010,
  title = {Permutation Importance: A Corrected Feature Importance Measure},
  volume = {26},
  issn = {1367-4803},
  shorttitle = {Permutation Importance},
  number = {10},
  journal = {Bioinformatics},
  doi = {10.1093/bioinformatics/btq134},
  author = {Altmann, Andr{\'e} and Tolo{\c s}i, Laura and Sander, Oliver and Lengauer, Thomas},
  month = may,
  year = {2010},
  pages = {1340-1347},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\2S7PR7XK\\Altmann et al_2010_Permutation importance.pdf;C:\\Users\\lissa102\\Zotero\\storage\\7MNB6K44\\Permutation-importance-a-corrected-feature.html}
}

@article{kwonIdentifyingRemovingDuplicate2015,
  title = {Identifying and Removing Duplicate Records from Systematic Review Searches},
  volume = {103},
  issn = {1536-5050},
  abstract = {Objective
The purpose of this study was to compare effectiveness of different options for de-duplicating records retrieved from systematic review searches.

Methods
Using the records from a published systematic review, five de-duplication options were compared. The time taken to de-duplicate in each option and the number of false positives (were deleted but should not have been) and false negatives (should have been deleted but were not) were recorded.

Results
The time for each option varied. The number of positive and false duplicates returned from each option also varied greatly.

Conclusion
The authors recommend different de-duplication options based on the skill level of the searcher and the purpose of de-duplication efforts.},
  number = {4},
  journal = {Journal of the Medical Library Association : JMLA},
  doi = {10.3163/1536-5050.103.4.004},
  author = {Kwon, Yoojin and Lemieux, Michelle and McTavish, Jill and Wathen, Nadine},
  month = oct,
  year = {2015},
  pages = {184-188},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\J5XKKZ2R\\Kwon et al_2015_Identifying and removing duplicate records from systematic review searches.pdf},
  pmid = {26512216},
  pmcid = {PMC4613377}
}

@misc{decosterMetaAnalysisNotes2004,
  title = {Meta-{{Analysis Notes}}},
  howpublished = {http://www.stat-help.com/notes.html},
  author = {DeCoster, Jamie},
  year = {2004},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\74GCBHEI\\DeCoster_2004_Meta-Analysis Notes.pdf}
}

@article{aloeEffectSizeRegression2012,
  title = {An {{Effect Size}} for {{Regression Predictors}} in {{Meta}}-{{Analysis}}},
  volume = {37},
  issn = {1076-9986, 1935-1054},
  language = {en},
  number = {2},
  journal = {Journal of Educational and Behavioral Statistics},
  doi = {10.3102/1076998610396901},
  author = {Aloe, A. M. and Becker, B. J.},
  month = apr,
  year = {2012},
  pages = {278-297},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\JFMSCW83\\Aloe_Becker_2012_An Effect Size for Regression Predictors in Meta-Analysis.pdf}
}

@article{liuMultivariateMetaAnalysisHeterogeneous2015,
  title = {Multivariate {{Meta}}-{{Analysis}} of {{Heterogeneous Studies Using Only Summary Statistics}}: {{Efficiency}} and {{Robustness}}},
  volume = {110},
  issn = {0162-1459},
  shorttitle = {Multivariate {{Meta}}-{{Analysis}} of {{Heterogeneous Studies Using Only Summary Statistics}}},
  abstract = {Meta-analysis has been widely used to synthesize evidence from multiple studies for common hypotheses or parameters of interest. However, it has not yet been fully developed for incorporating heterogeneous studies, which arise often in applications due to different study designs, populations or outcomes. For heterogeneous studies, the parameter of interest may not be estimable for certain studies, and in such a case, these studies are typically excluded from conventional meta-analysis. The exclusion of part of the studies can lead to a non-negligible loss of information. This paper introduces a metaanalysis for heterogeneous studies by combining the confidence density functions derived from the summary statistics of individual studies, hence referred to as the CD approach. It includes all the studies in the analysis and makes use of all information, direct as well as indirect. Under a general likelihood inference framework, this new approach is shown to have several desirable properties, including: i) it is asymptotically as efficient as the maximum likelihood approach using individual participant data (IPD) from all studies; ii) unlike the IPD analysis, it suffices to use summary statistics to carry out the CD approach. Individual-level data are not required; and iii) it is robust against misspecification of the working covariance structure of the parameter estimates. Besides its own theoretical significance, the last property also substantially broadens the applicability of the CD approach. All the properties of the CD approach are further confirmed by data simulated from a randomized clinical trials setting as well as by real data on aircraft landing performance. Overall, one obtains an unifying approach for combining summary statistics, subsuming many of the existing meta-analysis methods as special cases.},
  language = {eng},
  number = {509},
  journal = {Journal of the American Statistical Association},
  doi = {10.1080/01621459.2014.899235},
  author = {Liu, Dungang and Liu, Regina and Xie, Minge},
  year = {2015},
  keywords = {combining information,complex evidence synthesis,confidence distribution,efficiency,generalized estimating equations,heterogeneous studies,indirect evidence,individual participant data,multivariate meta-analysis},
  pages = {326-340},
  pmid = {26190875},
  pmcid = {PMC4504219}
}

@article{liMetaCARTToolIdentify2017,
  title = {Meta-{{CART}}: {{A}} Tool to Identify Interactions between Moderators in Meta-Analysis},
  journal = {British Journal of Mathematical and Statistical Psychology},
  author = {Li, Xinru and Dusseldorp, Elise and Meulman, Jacqueline J.},
  year = {2017},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\86NFTRA6\\Li et al_2017_Meta-CART.pdf}
}

@techreport{chenUsingRandomForest2004,
  address = {{Berkeley, CA, USA}},
  type = {Technical {{Report}}},
  title = {Using {{Random Forest}} to {{Learn Imbalanced Data}}},
  number = {666},
  institution = {{Department of Statistics, University of California}},
  author = {Chen, Chao and Liaw, Andy and Breiman, Leo},
  year = {2004},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\49PCRCCE\\Chen et al_2004_Using Random Forest to Learn Imbalanced Data.pdf}
}

@article{viechtbauerPackageMetafor2015,
  title = {Package `Metafor'},
  journal = {The Comprehensive R Archive Network. Package `metafor'. http://cran. r-project. org/web/packages/metafor/metafor. pdf},
  author = {Viechtbauer, Wolfgang and Viechtbauer, Maintainer Wolfgang},
  year = {2015},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\95W3IF53\\metafor.pdf;C:\\Users\\lissa102\\Zotero\\storage\\FE8TGH94\\metafor (1) documentation.pdf}
}

@article{liNetworkMetaanalysishighlyAttractive2011,
  title = {Network Meta-Analysis-Highly Attractive but More Methodological Research Is Needed},
  volume = {9},
  issn = {1741-7015},
  abstract = {Network meta-analysis, in the context of a systematic review, is a meta-analysis in which multiple treatments (that is, three or more) are being compared using both direct comparisons of interventions within randomized controlled trials and indirect comparisons across trials based on a common comparator. To ensure validity of findings from network meta-analyses, the systematic review must be designed rigorously and conducted carefully. Aspects of designing and conducting a systematic review for network meta-analysis include defining the review question, specifying eligibility criteria, searching for and selecting studies, assessing risk of bias and quality of evidence, conducting a network meta-analysis, interpreting and reporting findings. This commentary summarizes the methodologic challenges and research opportunities for network meta-analysis relevant to each aspect of the systematic review process based on discussions at a network meta-analysis methodology meeting we hosted in May 2010 at the Johns Hopkins Bloomberg School of Public Health. Since this commentary reflects the discussion at that meeting, it is not intended to provide an overview of the field.},
  journal = {BMC Medicine},
  doi = {10.1186/1741-7015-9-79},
  author = {Li, Tianjing and Puhan, Milo A. and Vedula, Swaroop S. and Singh, Sonal and Dickersin, Kay},
  year = {2011},
  pages = {79},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\A9I8B6AH\\Li et al_2011_Network meta-analysis-highly attractive but more methodological research is.pdf;C:\\Users\\lissa102\\Zotero\\storage\\3759Q6MR\\1741-7015-9-79.html}
}

@article{frickMixtureModelsStatistics,
  title = {Mixture {{Models}} in {{Statistics}} and {{Psychometrics}}\textendash{{Detecting Subgroups}} and {{Differential Item Functioning}}},
  author = {Frick, Hannah},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\87NFJWSG\\Frick_Mixture Models in Statistics and Psychometrics–Detecting Subgroups and.pdf}
}

@article{stroblIntroductionRecursivePartitioning2009,
  title = {An Introduction to Recursive Partitioning: {{Rationale}}, Application, and Characteristics of Classification and Regression Trees, Bagging, and Random Forests},
  volume = {14},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  shorttitle = {An Introduction to Recursive Partitioning},
  abstract = {Recursive partitioning methods have become popular and widely used tools for nonparametric regression and classification in many scientific fields. Especially random forests, which can deal with large numbers of predictor variables even in the presence of complex interactions, have been applied successfully in genetics, clinical medicine, and bioinformatics within the past few years. High-dimensional problems are common not only in genetics, but also in some areas of psychological research, where only a few subjects can be measured because of time or cost constraints, yet a large amount of data is generated for each subject. Random forests have been shown to achieve a high prediction accuracy in such applications and to provide descriptive variable importance measures reflecting the impact of each variable in both main effects and interactions. The aim of this work is to introduce the principles of the standard recursive partitioning methods as well as recent methodological improvements, to illustrate their usage for low and high-dimensional data exploration, but also to point out limitations of the methods and potential pitfalls in their practical application. Application of the methods is illustrated with freely available implementations in the R system for statistical computing.},
  language = {English},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/a0016973},
  author = {Strobl, Carolin and Malley, James and Tutz, Gerhard},
  year = {2009},
  keywords = {*Statistical Analysis,*Prediction,*Statistical Regression,Statistical Variables},
  pages = {323-348},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\XJUZCWWV\\Strobl et al_2009_An introduction to recursive partitioning.pdf}
}

@article{rileyInterpretationRandomEffects2011,
  title = {Interpretation of Random Effects Meta-Analyses},
  volume = {342},
  copyright = {\textcopyright{} BMJ Publishing Group Ltd 2011},
  issn = {0959-8138, 1468-5833},
  abstract = {{$<$}p{$>$}Summary estimates of treatment effect from random effects meta-analysis give only the average effect across all studies. Inclusion of prediction intervals, which estimate the likely effect in an individual setting, could make it easier to apply the results to clinical practice {$<$}/p{$>$}},
  language = {en},
  journal = {BMJ},
  doi = {10.1136/bmj.d549},
  author = {Riley, Richard D. and Higgins, Julian P. T. and Deeks, Jonathan J.},
  month = feb,
  year = {2011},
  pages = {d549},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\2VB535A6\\bmj.html},
  pmid = {21310794}
}

@article{nguyenUnbiasedFeatureSelection2015,
  title = {Unbiased {{Feature Selection}} in {{Learning Random Forests}} for {{High}}-{{Dimensional Data}}},
  volume = {2015},
  issn = {2356-6140},
  abstract = {Random forests (RFs) have been widely used as a powerful classification method. However, with the randomization in both bagging samples and feature selection, the trees in the forest tend to select uninformative features for node splitting. This makes RFs have poor accuracy when working with high-dimensional data. Besides that, RFs have bias in the feature selection process where multivalued features are favored. Aiming at debiasing feature selection in RFs, we propose a new RF algorithm, called xRF, to select good features in learning RFs for high-dimensional data. We first remove the uninformative features using -value assessment, and the subset of unbiased features is then selected based on some statistical measures. This feature subset is then partitioned into two subsets. A feature weighting sampling technique is used to sample features from these two subsets for building trees. This approach enables one to generate more accurate trees, while allowing one to reduce dimensionality and the amount of data needed for learning RFs. An extensive set of experiments has been conducted on 47 high-dimensional real-world datasets including image datasets. The experimental results have shown that RFs with the proposed approach outperformed the existing random forests in increasing the accuracy and the AUC measures.},
  language = {en},
  journal = {The Scientific World Journal},
  doi = {10.1155/2015/471371},
  author = {Nguyen, Thanh-Tung and Huang, Joshua Zhexue and Nguyen, Thuy Thi},
  month = mar,
  year = {2015},
  pages = {e471371},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\3UIRJNHF\\471371.html;C:\\Users\\lissa102\\Zotero\\storage\\UW3NRSKR\\Nguyen et al_2015_Unbiased Feature Selection in Learning Random Forests for High-Dimensional Data.pdf},
  pmid = {25879059}
}

@article{harlowBigDataPsychology2016,
  title = {Big Data in Psychology: {{Introduction}} to the Special Issue.},
  volume = {21},
  issn = {1939-1463, 1082-989X},
  shorttitle = {Big Data in Psychology},
  language = {en},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/met0000120},
  author = {Harlow, Lisa L. and Oswald, Frederick L.},
  year = {2016},
  pages = {447-457},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\ZWZ5DHNS\\Harlow_Oswald_2016_Big data in psychology.pdf}
}

@article{millerFindingStructureData2016,
  title = {Finding Structure in Data Using Multivariate Tree Boosting},
  volume = {21},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  abstract = {Technology and collaboration enable dramatic increases in the size of psychological and psychiatric data collections, but finding structure in these large data sets with many collected variables is challenging. Decision tree ensembles such as random forests (Strobl, Malley, \& Tutz, 2009) are a useful tool for finding structure, but are difficult to interpret with multiple outcome variables which are often of interest in psychology. To find and interpret structure in data sets with multiple outcomes and many predictors (possibly exceeding the sample size), we introduce a multivariate extension to a decision tree ensemble method called gradient boosted regression trees (Friedman, 2001). Our extension, multivariate tree boosting, is a method for nonparametric regression that is useful for identifying important predictors, detecting predictors with nonlinear effects and interactions without specification of such effects, and for identifying predictors that cause 2 or more outcome variables to covary. We provide the R package ``mvtboost'' to estimate, tune, and interpret the resulting model, which extends the implementation of univariate boosting in the R package ``gbm'' (Ridgeway, 2015) to continuous, multivariate outcomes. To illustrate the approach, we analyze predictors of psychological well-being (Ryff \& Keyes, 1995). Simulations verify that our approach identifies predictors with nonlinear effects and achieves high prediction accuracy, exceeding or matching the performance of (penalized) multivariate multiple regression and multivariate decision trees over a wide range of conditions.},
  language = {English},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/met0000087},
  author = {Miller, Patrick J. and Lubke, Gitta H. and McArtor, Daniel B. and S, C.},
  year = {2016},
  keywords = {*Statistical Regression,*Decision Making,*Multivariate Analysis,*Nonparametric Statistical Tests,Computational Modeling},
  pages = {583-602},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\S9VEH69Z\\Miller et al_2016_Finding structure in data using multivariate tree boosting.pdf}
}

@article{brandmaierTheoryguidedExplorationStructural2016,
  title = {Theory-Guided Exploration with Structural Equation Model Forests},
  volume = {21},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  abstract = {Structural equation model (SEM) trees, a combination of SEMs and decision trees, have been proposed as a data-analytic tool for theory-guided exploration of empirical data. With respect to a hypothesized model of multivariate outcomes, such trees recursively find subgroups with similar patterns of observed data. SEM trees allow for the automatic selection of variables that predict differences across individuals in specific theoretical models, for instance, differences in latent factor profiles or developmental trajectories. However, SEM trees are unstable when small variations in the data can result in different trees. As a remedy, SEM forests, which are ensembles of SEM trees based on resamplings of the original dataset, provide increased stability. Because large forests are less suitable for visual inspection and interpretation, aggregate measures provide researchers with hints on how to improve their models: (a) variable importance is based on random permutations of the out-of-bag (OOB) samples of the individual trees and quantifies, for each variable, the average reduction of uncertainty about the model-predicted distribution; and (b) case proximity enables researchers to perform clustering and outlier detection. We provide an overview of SEM forests and illustrate their utility in the context of cross-sectional factor models of intelligence and episodic memory. We discuss benefits and limitations, and provide advice on how and when to use SEM trees and forests in future research.},
  language = {English},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/met0000090},
  author = {Brandmaier, Andreas M. and Prindle, John J. and McArdle, John J. and Lindenberger, Ulman},
  year = {2016},
  keywords = {Intelligence,*Structural Equation Modeling,*Statistical Variables,*Decision Making,*Computational Modeling,Episodic Memory},
  pages = {566-582},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\2V5NVZPK\\Brandmaier et al_2016_Theory-guided exploration with structural equation model forests.pdf}
}

@article{chenPracticalGuideBig2016,
  title = {A Practical Guide to Big Data Research in Psychology},
  volume = {21},
  copyright = {(c) 2016 APA, all rights reserved},
  issn = {1939-1463 1082-989X},
  abstract = {The massive volume of data that now covers a wide variety of human behaviors offers researchers in psychology an unprecedented opportunity to conduct innovative theory- and data-driven field research. This article is a practical guide to conducting big data research, covering data management, acquisition, processing, and analytics (including key supervised and unsupervised learning data mining methods). It is accompanied by walkthrough tutorials on data acquisition, text analysis with latent Dirichlet allocation topic modeling, and classification with support vector machines. Big data practitioners in academia, industry, and the community have built a comprehensive base of tools and knowledge that makes big data research accessible to researchers in a broad range of fields. However, big data research does require knowledge of software programming and a different analytical mindset. For those willing to acquire the requisite skills, innovative analyses of unexpected or previously untapped data sources can offer fresh ways to develop, test, and extend theories. When conducted with care and respect, big data research can become an essential complement to traditional research.},
  language = {English},
  number = {4},
  journal = {Psychological Methods},
  doi = {10.1037/met0000111},
  author = {Chen, Eric Evan and Wojcik, Sean P.},
  year = {2016},
  keywords = {*Statistical Analysis,*Psychology,*Data Mining,*Data Processing,*Machine Learning,Databases},
  pages = {458-474},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\RM35QGSD\\Chen_Wojcik_2016_A practical guide to big data research in psychology.pdf}
}

@article{bowmanEffectSizesStatistical2012,
  title = {Effect {{Sizes}} and {{Statistical Methods}} for {{Meta}}-{{Analysis}} in {{Higher Education}}},
  volume = {53},
  issn = {0361-0365, 1573-188X},
  language = {en},
  number = {3},
  journal = {Research in Higher Education},
  doi = {10.1007/s11162-011-9232-5},
  author = {Bowman, Nicholas A.},
  month = may,
  year = {2012},
  pages = {375-382},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\CBUI824R\\Bowman_2012_Effect Sizes and Statistical Methods for Meta-Analysis in Higher Education.pdf}
}

@article{hozoEstimatingMeanVariance2005,
  title = {Estimating the Mean and Variance from the Median, Range, and the Size of a Sample},
  volume = {5},
  issn = {1471-2288},
  abstract = {Usually the researchers performing meta-analysis of continuous outcomes from clinical trials need their mean value and the variance (or standard deviation) in order to pool data. However, sometimes the published reports of clinical trials only report the median, range and the size of the trial.},
  journal = {BMC Medical Research Methodology},
  doi = {10.1186/1471-2288-5-13},
  author = {Hozo, Stela Pudar and Djulbegovic, Benjamin and Hozo, Iztok},
  year = {2005},
  pages = {13},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\5Z2JPE6B\\Hozo et al_2005_Estimating the mean and variance from the median, range, and the size of a.pdf;C:\\Users\\lissa102\\Zotero\\storage\\WXC6KDI4\\1471-2288-5-13.html}
}

@misc{MendeleyDetectingDuplicates,
  title = {Mendeley | {{Detecting Duplicates}}},
  howpublished = {http://support.mendeley.com/customer/en/portal/articles/170038-detecting-duplicates},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\8F6BCE7D\\170038-detecting-duplicates.html}
}

@article{viechtbauerConductingMetaanalysesMetafor2010,
  title = {Conducting Meta-Analyses in {{R}} with the Metafor Package},
  volume = {36},
  number = {3},
  journal = {J Stat Softw},
  author = {Viechtbauer, Wolfgang and others},
  year = {2010},
  pages = {1--48},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\SKIFUP3J\\Viechtbauer_others_2010_Conducting meta-analyses in R with the metafor package.pdf}
}

@article{xuCaseSpecificRandomForests2016,
  title = {Case-{{Specific Random Forests}}},
  volume = {25},
  issn = {1061-8600, 1537-2715},
  language = {en},
  number = {1},
  journal = {Journal of Computational and Graphical Statistics},
  doi = {10.1080/10618600.2014.983641},
  author = {Xu, Ruo and Nettleton, Dan and Nordman, Daniel J.},
  month = jan,
  year = {2016},
  pages = {49-65},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\7F2WTTR3\\Xu et al_2016_Case-Specific Random Forests.pdf}
}

@misc{HandlingCaseWeight,
  title = {Handling Case Weight in the {{Random Forest}} Packages in {{R}} - {{Cross Validated}}},
  howpublished = {http://stats.stackexchange.com/questions/166424/handling-case-weight-in-the-random-forest-packages-in-r},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\UEG7E4NF\\handling-case-weight-in-the-random-forest-packages-in-r.html}
}

@article{borensteinMetaanalysisFixedEffect2007,
  title = {Meta-Analysis: {{Fixed}} Effect vs. Random Effects},
  shorttitle = {Meta-Analysis},
  journal = {Meta-analysis. com},
  author = {Borenstein, Michael and Hedges, Larry and Rothstein, Hannah},
  year = {2007},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\97MZBRFT\\Borenstein et al_2007_Meta-analysis.pdf}
}

@misc{WeightingMoreRecenta,
  title = {R - {{Weighting}} More Recent Data in {{Random Forest}} Model - {{Cross Validated}}},
  howpublished = {http://stats.stackexchange.com/questions/83104/weighting-more-recent-data-in-random-forest-model},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\S8AUVWTC\\weighting-more-recent-data-in-random-forest-model.html}
}

@misc{BootstrappingMetaAnalyticModels,
  title = {Bootstrapping with {{Meta}}-{{Analytic Models}} [{{The}} Metafor {{Package}}]},
  howpublished = {http://www.metafor-project.org/doku.php/tips:bootstrapping\_with\_ma}
}

@article{lopez-lopezEstimationPredictivePower2014,
  title = {Estimation of the Predictive Power of the Model in Mixed-Effects Meta-Regression: {{A}} Simulation Study},
  volume = {67},
  issn = {00071102},
  shorttitle = {Estimation of the Predictive Power of the Model in Mixed-Effects Meta-Regression},
  language = {en},
  number = {1},
  journal = {British Journal of Mathematical and Statistical Psychology},
  doi = {10.1111/bmsp.12002},
  author = {{L{\'o}pez-L{\'o}pez}, Jos{\'e} Antonio and {Mar{\'i}n-Mart{\'i}nez}, Fulgencio and {S{\'a}nchez-Meca}, Julio and {Van den Noortgate}, Wim and Viechtbauer, Wolfgang},
  month = feb,
  year = {2014},
  pages = {30-48},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\FS8QSJFI\\López-López et al. - 2014 - Estimation of the predictive power of the model in.pdf}
}

@misc{vanlissaMetaforestExploringHeterogeneity2017,
  title = {Metaforest: {{Exploring Heterogeneity}} in {{Meta}}-{{Analysis}} Using {{Random Forests}}},
  author = {Van Lissa, Caspar J.},
  year = {2017}
}

@article{vandennoortgateMetaanalysisMultipleOutcomes2015,
  title = {Meta-Analysis of Multiple Outcomes: A Multilevel Approach},
  volume = {47},
  issn = {1554-3528},
  shorttitle = {Meta-Analysis of Multiple Outcomes},
  language = {en},
  number = {4},
  journal = {Behavior Research Methods},
  doi = {10.3758/s13428-014-0527-2},
  author = {{Van den Noortgate}, Wim and {L{\'o}pez-L{\'o}pez}, Jos{\'e} Antonio and {Mar{\'i}n-Mart{\'i}nez}, Fulgencio and {S{\'a}nchez-Meca}, Julio},
  month = dec,
  year = {2015},
  pages = {1274-1294},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\EQZ9ZIU9\\Van den Noortgate et al. - 2015 - Meta-analysis of multiple outcomes a multilevel a.pdf;C:\\Users\\lissa102\\Zotero\\storage\\HHH5BIIQ\\vandennoortgate2014.pdf}
}

@book{hastieElementsStatisticalLearning2009,
  address = {{New York}},
  edition = {Second},
  title = {The Elements of Statistical Learning: {{Data}} Mining, Inference, and Prediction},
  publisher = {{Springer}},
  author = {Hastie, Trevor and Tibshirani, Robert and Friedman, Jerome},
  year = {2009},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\9SNFR93Q\\Elements of statistical learning.pdf}
}

@article{buhlmannAnalyzingBagging2002,
  title = {Analyzing Bagging},
  volume = {30},
  issn = {0090-5364},
  abstract = {Bagging is one of the most effective computationally intensive procedures to improve on unstable estimators or classifiers, useful especially for high dimensional data set problems. Here we formalize the notion of instability and derive theoretical results to analyze the variance reduction effect of bagging (or variants thereof) in mainly hard decision problems, which include estimation after testing in regression and decision trees for regression functions and classifiers. Hard decisions create instability, and bagging is shown to smooth such hard decisions, yielding smaller variance and mean squared error. With theoretical explanations, we motivate subagging based on subsampling as an alternative aggregation scheme. It is computationally cheaper but still shows approximately the same accuracy as bagging. Moreover, our theory reveals improvements in first order and in line with simulation studies. In particular, we obtain an asymptotic limiting distribution at the cube-root rate for the split point when fitting piecewise constant functions. Denoting sample size by n, it follows that in a cylindric neighborhood of diameter n-1/3 of the theoretically optimal split point, the variance and mean squared error reduction of subagging can be characterized analytically. Because of the slow rate, our reasoning also provides an explanation on the global scale for the whole covariate space in a decision tree with finitely many splits.},
  number = {4},
  journal = {The Annals of Statistics},
  doi = {10.2307/1558692},
  author = {B{\"u}hlmann, Peter and Yu, Bin},
  year = {2002},
  pages = {927-961}
}

@article{breimanRandomForests2001,
  title = {Random Forests},
  volume = {45},
  issn = {0885-6125, 1573-0565},
  abstract = {Random forests are a combination of tree predictors such that each tree depends on the values of a random vector sampled independently and with the same distribution for all trees in the forest. The generalization error for forests converges a.s. to a limit as the number of trees in the forest becomes large. The generalization error of a forest of tree classifiers depends on the strength of the individual trees in the forest and the correlation between them. Using a random selection of features to split each node yields error rates that compare favorably to Adaboost (Y. Freund \& R. Schapire, Machine Learning: Proceedings of the Thirteenth International conference, ***, 148\textendash{}156), but are more robust with respect to noise. Internal estimates monitor error, strength, and correlation and these are used to show the response to increasing the number of features used in the splitting. Internal estimates are also used to measure variable importance. These ideas are also applicable to regression.},
  language = {en},
  number = {1},
  journal = {Machine Learning},
  doi = {10.1023/A:1010933404324},
  author = {Breiman, Leo},
  month = oct,
  year = {2001},
  pages = {5-32},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GZR9BSR9\\Breiman_2001_Random Forests.pdf;C:\\Users\\lissa102\\Zotero\\storage\\42HXJR97\\10.html}
}

@article{vanlissaMetaForestExploringHeterogeneity2017,
  title = {{{MetaForest}}: {{Exploring}} Heterogeneity in Meta-Analysis Using Random Forests},
  shorttitle = {{{MetaForest}}},
  abstract = {Meta-analyses in psychology often lack the power to adequately account for between-studies heterogeneity. The number of studies on any topic is typically low, because research is cost- and time-intensive. At the same time, a host of potential moderators are introduced when similar research questions are examined in different labs, sampling from different populations, using idiosyncratic methods and instrumentation. Such between-studies heterogeneity presents a substantial challenge to data aggregation in classic meta-analysis. When the causes for heterogeneity are known a-priori, they can be accounted for using meta-regression. What is currently lacking, however, is an exploratory approach, to be used when heterogeneity is suspected, but it is not known which moderators most strongly influence the observed effect size. Recently, weighted regression trees have been used to explore heterogeneity in meta-analysis. Although this provides a promising first step, single trees have many limitations, which can be overcome by using random forests: A powerful learning algorithm, which is flexible, yet relatively robust to overfitting. The present paper introduces MetaForest: An adaptation of random forests for meta-analysis. We present two simulation studies, which illustrate that, in datasets as small as 20 cases, MetaForest outperforms single trees, in terms of three metrics: 1) Predictive performance; 2) power, as evidenced by the proportion of datasets in which the algorithm achieved a positive R2cv; and 3) the ability to distinguish relevant moderators from irrelevant moderators, using variable importance measures. We discuss how MetaForest can enhance the exploration of between-studies heterogeneity when conducting meta-analyses in diverse bodies of literature. 
    Hosted on the Open Science Framework},
  language = {en},
  journal = {Open Science Framework},
  doi = {10.17605/OSF.IO/KHJGB},
  author = {Van Lissa, Caspar J.},
  month = sep,
  year = {2017},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\B3ZCS848\\khjgb.html}
}

@article{grebePCurveSelectionMethods2017,
  title = {P-{{Curve}} and {{Selection Methods}} as {{Meta}}-{{Analytic Supplements}} for {{Biologists}}: {{A Demonstration}} of {{Effect Size Estimation}} in {{Studies}} of {{Human Fluctuating Asymmetry}}},
  volume = {9},
  issn = {2073-8994},
  shorttitle = {P-{{Curve}} and {{Selection Methods}} as {{Meta}}-{{Analytic Supplements}} for {{Biologists}}},
  language = {en},
  number = {7},
  journal = {Symmetry},
  doi = {10.3390/sym9070098},
  author = {Grebe, Nicholas and Falcon, Rachael and Gangestad, Steven},
  month = jun,
  year = {2017},
  pages = {98},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\HF7DF7DC\\P-Curve meta-analysis.pdf}
}

@misc{30TrimandFillFull2014,
  title = {[30] {{Trim}}-and-{{Fill}} Is {{Full}} of {{It}} (Bias)},
  abstract = {Statistically significant findings are much more likely to be published than non-significant ones (no citation necessary). Because overestimated effects are more likely to be statistically signific\ldots{}},
  journal = {Data Colada},
  month = dec,
  year = {2014},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\JKS7DJDB\\30.html}
}

@misc{rcoreteamLanguageEnvironmentStatistical2017a,
  address = {{Vienna, Austria}},
  title = {R: {{A Language}} and {{Environment}} for {{Statistical Computing}}},
  howpublished = {R Foundation for Statistical Computing},
  author = {R Core Team},
  year = {2017}
}

@article{lawsPsychologyReplication2016,
  title = {Psychology, Replication \& Beyond},
  volume = {4},
  issn = {2050-7283},
  abstract = {Modern psychology is apparently in crisis and the prevailing view is that this partly reflects an inability to replicate past findings. If a crisis does exists, then it is some kind of `chronic' crisis, as psychologists have been censuring themselves over replicability for decades. While the debate in psychology is not new, the lack of progress across the decades is disappointing. Recently though, we have seen a veritable surfeit of debate alongside multiple orchestrated and well-publicised replication initiatives. The spotlight is being shone on certain areas and although not everyone agrees on how we should interpret the outcomes, the debate is happening and impassioned. The issue of reproducibility occupies a central place in our whig history of psychology.},
  journal = {BMC Psychology},
  doi = {10.1186/s40359-016-0135-2},
  author = {Laws, Keith R.},
  month = jun,
  year = {2016},
  pages = {30},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\VPRSUHVG\\Laws_2016_Psychology, replication & beyond.pdf;C:\\Users\\lissa102\\Zotero\\storage\\AHCGKZST\\s40359-016-0135-2.html}
}

@article{swiatkowskiReplicabilityCrisisSocial2017,
  title = {Replicability {{Crisis}} in {{Social Psychology}}: {{Looking}} at the {{Past}} to {{Find New Pathways}} for the {{Future}}},
  volume = {30},
  copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are \textcopyright, \textregistered{} or \texttrademark{} of their respective owners. No challenge to any owner's rights is intended or should be inferred.},
  issn = {2397-8570},
  shorttitle = {Replicability {{Crisis}} in {{Social Psychology}}},
  abstract = {Article: Replicability Crisis in Social Psychology: Looking at the Past to Find New Pathways for the Future},
  language = {eng},
  number = {1},
  journal = {International Review of Social Psychology},
  doi = {10.5334/irsp.66},
  author = {{\'S}wi{\k{a}}tkowski, Wojciech and Dompnier, Beno{\^i}t},
  month = may,
  year = {2017},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GJDMFVCJ\\Świątkowski_Dompnier_2017_Replicability Crisis in Social Psychology.pdf;C:\\Users\\lissa102\\Zotero\\storage\\S9W72R58\\irsp.html}
}

@article{jacksonQuantifyingImpactBetweenstudy2012,
  title = {Quantifying the Impact of Between-Study Heterogeneity in Multivariate Meta-Analyses},
  volume = {31},
  issn = {0277-6715},
  abstract = {Measures that quantify the impact of heterogeneity in univariate meta-analysis, including the very popular I2 statistic, are now well established. Multivariate meta-analysis, where studies provide multiple outcomes that are pooled in a single analysis, is also becoming more commonly used. The question of how to quantify heterogeneity in the multivariate setting is therefore raised. It is the univariate R2 statistic, the ratio of the variance of the estimated treatment effect under the random and fixed effects models, that generalises most naturally, so this statistic provides our basis. This statistic is then used to derive a multivariate analogue of I2, which we call . We also provide a multivariate H2 statistic, the ratio of a generalisation of Cochran's heterogeneity statistic and its associated degrees of freedom, with an accompanying generalisation of the usual I2 statistic, . Our proposed heterogeneity statistics can be used alongside all the usual estimates and inferential procedures used in multivariate meta-analysis. We apply our methods to some real datasets and show how our statistics are equally appropriate in the context of multivariate meta-regression, where study level covariate effects are included in the model. Our heterogeneity statistics may be used when applying any procedure for fitting the multivariate random effects model. Copyright \textcopyright{} 2012 John Wiley \& Sons, Ltd.},
  number = {29},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.5453},
  author = {Jackson, Dan and White, Ian R and Riley, Richard D},
  month = dec,
  year = {2012},
  pages = {3805-3820},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\RVT5ZWMJ\\Jackson et al_2012_Quantifying the impact of between-study heterogeneity in multivariate.pdf},
  pmid = {22763950},
  pmcid = {PMC3546377}
}

@article{petropoulouComparison20Heterogeneity,
  title = {A Comparison of 20 Heterogeneity Variance Estimators in Statistical Synthesis of Results from Studies: {{A}} Simulation Study},
  issn = {1097-0258},
  shorttitle = {A Comparison of 20 Heterogeneity Variance Estimators in Statistical Synthesis of Results from Studies},
  abstract = {When we synthesize research findings via meta-analysis, it is common to assume that the true underlying effect differs across studies. Total variability consists of the within-study and between-study variances (heterogeneity). There have been established measures, such as I2, to quantify the proportion of the total variation attributed to heterogeneity. There is a plethora of estimation methods available for estimating heterogeneity. The widely used DerSimonian and Laird estimation method has been challenged, but knowledge of the overall performance of heterogeneity estimators is incomplete. We identified 20 heterogeneity estimators in the literature and evaluated their performance in terms of mean absolute estimation error, coverage probability, and length of the confidence interval for the summary effect via a simulation study. Although previous simulation studies have suggested the Paule-Mandel estimator, it has not been compared with all the available estimators. For dichotomous outcomes, estimating heterogeneity through Markov chain Monte Carlo is a good choice if an informative prior distribution for heterogeneity is employed (eg, by published Cochrane reviews). Nonparametric bootstrap and positive DerSimonian and Laird perform well for all assessment criteria for both dichotomous and continuous outcomes. Hartung-Makambi estimator can be the best choice when the heterogeneity values are close to 0.07 for dichotomous outcomes and medium heterogeneity values (0.01\,,\,0.05) for continuous outcomes. Hence, there are heterogeneity estimators (nonparametric bootstrap DerSimonian and Laird and positive DerSimonian and Laird) that perform better than the suggested Paule-Mandel. Maximum likelihood provides the best performance for both types of outcome in the absence of heterogeneity.},
  language = {en},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.7431},
  author = {Petropoulou, Maria and Mavridis, Dimitris},
  keywords = {coverage probability,heterogeneity variance estimators,length of confidence interval,mean absolute estimation error,simulation study},
  pages = {n/a-n/a},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\TBAHVGNU\\abstract.html}
}

@misc{CheckingPackagePackages,
  title = {Checking a Package {$\cdot$} {{R}} Packages},
  howpublished = {http://r-pkgs.had.co.nz/check.html\#travis}
}

@misc{ReleasingPackagePackages,
  title = {Releasing a Package {$\cdot$} {{R}} Packages},
  howpublished = {http://r-pkgs.had.co.nz/release.html}
}

@article{leischCreatingPackagesTutorial2008,
  title = {Creating r Packages: {{A}} Tutorial},
  shorttitle = {Creating r Packages},
  author = {Leisch, Friedrich},
  year = {2008},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\DJQAJAS9\\Leisch-CreatingPackages.pdf}
}

@article{lyonWhyAreNormal2013,
  title = {Why Are Normal Distributions Normal?},
  volume = {65},
  number = {3},
  journal = {The British Journal for the Philosophy of Science},
  doi = {10.1093/bjps/axs046},
  author = {Lyon, Aidan},
  year = {2013},
  pages = {621--649},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\FXEXZENP\\Lyon-normal_distributions.pdf}
}

@incollection{svetnikApplicationBreimanRandom2004,
  address = {{Berlin, Heidelberg}},
  title = {Application of {{Breiman}}'s {{Random Forest}} to {{Modeling Structure}}-{{Activity Relationships}} of {{Pharmaceutical Molecules}}},
  isbn = {978-3-540-22144-9 978-3-540-25966-4},
  language = {en},
  booktitle = {Lecture {{Notes}} in {{Computer Science}}: {{Multiple Classifier}} Systems.},
  publisher = {{Springer}},
  author = {Svetnik, Vladimir and Liaw, Andy and Tong, Christopher and Wang, Ting},
  editor = {Roli, F. and Kittler, J. and Windeatt},
  year = {2004},
  pages = {334-343},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\Z2T4I66X\\978-3-540-25966-4_33.html}
}

@article{stroblBiasRandomForest2007,
  title = {Bias in Random Forest Variable Importance Measures: {{Illustrations}}, Sources and a Solution},
  volume = {8},
  shorttitle = {Bias in Random Forest Variable Importance Measures},
  abstract = {Variable importance measures for random forests have been receiving increased attention as a means of variable selection in many classification tasks in bioinformatics and related scientific fields, for instance to select a subset of genetic markers relevant for the prediction of a certain disease. We show that random forest variable importance measures are a sensible means for variable selection in many applications, but are not reliable in situations where potential predictor variables vary in their scale of measurement or their number of categories. This is particularly important in genomics and computational biology, where predictors often include variables of different types, for example when predictors include both sequence data and continuous variables such as folding energy, or when amino acid sequence data show different numbers of categories.},
  journal = {BMC Bioinformatics},
  doi = {10.1186/1471-2105-8-25},
  author = {Strobl, Carolin and Boulesteix, Anne-Laure and Zeileis, Achim and Hothorn, Torsten},
  month = jan,
  year = {2007},
  pages = {25},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\RUSV4JJ3\\Strobl et al_2007_Bias in random forest variable importance measures.pdf;C:\\Users\\lissa102\\Zotero\\storage\\PZDC522W\\1471-2105-8-25.html}
}

@misc{RPubsShortGuide,
  title = {{{RPubs}} - {{Short}} Guide to Creating {{APA}} Documents with {{R Markdown}} and Papaja},
  howpublished = {https://rpubs.com/YaRrr/papaja\_guide}
}

@misc{HappyCollaborationRmd,
  title = {Happy Collaboration with {{Rmd}} to Docx},
  howpublished = {http://rmarkdown.rstudio.com/articles\_docx.html}
}

@article{thompsonHowShouldMetaregression2002,
  title = {How Should Meta-Regression Analyses Be Undertaken and Interpreted?},
  volume = {21},
  issn = {1097-0258},
  abstract = {Appropriate methods for meta-regression applied to a set of clinical trials, and the limitations and pitfalls in interpretation, are insufficiently recognized. Here we summarize recent research focusing on these issues, and consider three published examples of meta-regression in the light of this work. One principal methodological issue is that meta-regression should be weighted to take account of both within-trial variances of treatment effects and the residual between-trial heterogeneity (that is, heterogeneity not explained by the covariates in the regression). This corresponds to random effects meta-regression. The associations derived from meta-regressions are observational, and have a weaker interpretation than the causal relationships derived from randomized comparisons. This applies particularly when averages of patient characteristics in each trial are used as covariates in the regression. Data dredging is the main pitfall in reaching reliable conclusions from meta-regression. It can only be avoided by prespecification of covariates that will be investigated as potential sources of heterogeneity. However, in practice this is not always easy to achieve. The examples considered in this paper show the tension between the scientific rationale for using meta-regression and the difficult interpretative problems to which such analyses are prone. Copyright \textcopyright{} 2002 John Wiley \& Sons, Ltd.},
  language = {en},
  number = {11},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.1187},
  author = {Thompson, Simon G. and Higgins, Julian P. T.},
  month = jun,
  year = {2002},
  keywords = {meta-analysis,heterogeneity,ecological associations,false positive results,meta-regression,study-level covariates},
  pages = {1559-1573},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\INMVCHG2\\abstract.html}
}

@article{hajjemMixedeffectsRandomForest2014,
  title = {Mixed-Effects Random Forest for Clustered Data},
  volume = {84},
  issn = {0094-9655},
  abstract = {This paper presents an extension of the random forest (RF) method to the case of clustered data. The proposed `mixed-effects random forest' (MERF) is implemented using a standard RF algorithm within the framework of the expectation\textendash{}maximization algorithm. Simulation results show that the proposed MERF method provides substantial improvements over standard RF when the random effects are non-negligible. The use of the method is illustrated to predict the first-week box office revenues of movies.},
  number = {6},
  journal = {Journal of Statistical Computation and Simulation},
  doi = {10.1080/00949655.2012.741599},
  author = {Hajjem, Ahlem and Bellavance, Fran{\c c}ois and Larocque, Denis},
  month = jun,
  year = {2014},
  keywords = {clustered data,mixed effects,random forest,regression tree},
  pages = {1313-1328},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\6T77EB9C\\Hajjem et al_2014_Mixed-effects random forest for clustered data.pdf;C:\\Users\\lissa102\\Zotero\\storage\\I5PQ3J7R\\00949655.2012.html}
}

@article{finchRecursivePartitioningPresence2015,
  title = {Recursive {{Partitioning}} in the {{Presence}} of {{Multilevel Data}}},
  volume = {41},
  number = {2},
  journal = {General Linear Model Journal},
  author = {Finch, W. Holmes},
  year = {2015},
  pages = {30-44},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\4DJCPSDW\\Finch_Recursive Partitioning in the Presence of Multilevel Data.pdf}
}

@article{karpievitchIntrospectiveComparisonRandom2009,
  title = {An {{Introspective Comparison}} of {{Random Forest}}-{{Based Classifiers}} for the {{Analysis}} of {{Cluster}}-{{Correlated Data}} by {{Way}} of {{RF}}++},
  volume = {4},
  issn = {1932-6203},
  abstract = {Many mass spectrometry-based studies, as well as other biological experiments produce cluster-correlated data. Failure to account for correlation among observations may result in a classification algorithm overfitting the training data and producing overoptimistic estimated error rates and may make subsequent classifications unreliable. Current common practice for dealing with replicated data is to average each subject replicate sample set, reducing the dataset size and incurring loss of information. In this manuscript we compare three approaches to dealing with cluster-correlated data: unmodified Breiman's Random Forest (URF), forest grown using subject-level averages (SLA), and RF++ with subject-level bootstrapping (SLB). RF++, a novel Random Forest-based algorithm implemented in C++, handles cluster-correlated data through a modification of the original resampling algorithm and accommodates subject-level classification. Subject-level bootstrapping is an alternative sampling method that obviates the need to average or otherwise reduce each set of replicates to a single independent sample. Our experiments show nearly identical median classification and variable selection accuracy for SLB forests and URF forests when applied to both simulated and real datasets. However, the run-time estimated error rate was severely underestimated for URF forests. Predictably, SLA forests were found to be more severely affected by the reduction in sample size which led to poorer classification and variable selection accuracy. Perhaps most importantly our results suggest that it is reasonable to utilize URF for the analysis of cluster-correlated data. Two caveats should be noted: first, correct classification error rates must be obtained using a separate test dataset, and second, an additional post-processing step is required to obtain subject-level classifications. RF++ is shown to be an effective alternative for classifying both clustered and non-clustered data. Source code and stand-alone compiled versions of command-line and easy-to-use graphical user interface (GUI) versions of RF++ for Windows and Linux as well as a user manual (Supplementary File S2) are available for download at: http://sourceforge.org/projects/rfpp/ under the GNU public license.},
  number = {9},
  journal = {PLOS ONE},
  doi = {10.1371/journal.pone.0007087},
  author = {Karpievitch, Yuliya V. and Hill, Elizabeth G. and Leclerc, Anthony P. and Dabney, Alan R. and Almeida, Jonas S.},
  month = sep,
  year = {2009},
  keywords = {Algorithms,Decision trees,Biomarkers,Decision tree learning,Forests,Matrix-assisted laser desorption ionization time-of-flight mass spectrometry,Normal distribution,Trees},
  pages = {e7087},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\QGA5PAQH\\Karpievitch et al_2009_An Introspective Comparison of Random Forest-Based Classifiers for the Analysis.pdf;C:\\Users\\lissa102\\Zotero\\storage\\IPUD4J5N\\article.html}
}

@article{knappImprovedTestsRandom2003,
  title = {Improved Tests for a Random Effects Meta-Regression with a Single Covariate},
  volume = {22},
  number = {17},
  journal = {Statistics in medicine},
  author = {Knapp, Guido and Hartung, Joachim},
  year = {2003},
  pages = {2693--2710},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\9XSUI7PZ\\knapp2003.pdf}
}

@article{vanerpEstimatesBetweenStudyHeterogeneity2017,
  title = {Estimates of {{Between}}-{{Study Heterogeneity}} for 705 {{Meta}}-{{Analyses Reported}} in {{Psychological Bulletin From}} 1990\textendash{}2013},
  volume = {5},
  number = {1},
  journal = {Journal of Open Psychology Data},
  author = {Van Erp, Sara and Verhagen, Josine and Grasman, Raoul PPP and Wagenmakers, Eric-Jan},
  year = {2017},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\2PSCDZB6\\jopd.html}
}

@article{higginsControllingRiskSpurious2004,
  title = {Controlling the Risk of Spurious Findings from Meta-Regression},
  volume = {23},
  number = {11},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.1752},
  author = {Higgins, Julian P T and Thompson, Simon G},
  year = {2004},
  pages = {1663-1682},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\YCXWZEG8\\higgins2004.pdf}
}

@article{genuerVariableSelectionUsing2010,
  title = {Variable Selection Using Random Forests},
  volume = {31},
  issn = {01678655},
  language = {en},
  number = {14},
  journal = {Pattern Recognition Letters},
  doi = {10.1016/j.patrec.2010.03.014},
  author = {Genuer, Robin and Poggi, Jean-Michel and {Tuleau-Malot}, Christine},
  month = oct,
  year = {2010},
  pages = {2225-2236},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\EX3KRZMD\\genuer2010.pdf}
}

@article{fabrigarConceptualizingEvaluatingReplication2016,
  series = {Rigorous and {{Replicable Methods}} in {{Social Psychology}}},
  title = {Conceptualizing and Evaluating the Replication of Research Results},
  volume = {66},
  issn = {0022-1031},
  abstract = {Many recent discussions have focused on the role of replication in psychological science. In this article, we examine three key issues in evaluating the conclusions that follow from results of studies at least partly aimed at replicating previous results: the evaluation and status of exact versus conceptual replications, the statistical evaluation of replications, and the robustness of research findings to potential existing or future ``non-replications.'' In the first section of the article, we discuss the sources of ambiguity in evaluating failures to replicate in exact as well as conceptual replications. In addressing these ambiguities, we emphasize the key role of psychometric invariance of the independent and dependent variables in evaluations of replications. In the second section of the article, we use a meta-analytic framework to discuss the statistical status of replication attempts. We emphasize meta-analytic tools that have been used too sparingly, especially in evaluation of sets of studies within a single article or focused program of research. In the final section of the article, we extend many of these meta-analytic tools to the evaluation of the robustness of a body of research to potential existing or future failures to replicate previous statistically significant results.},
  journal = {Journal of Experimental Social Psychology},
  doi = {10.1016/j.jesp.2015.07.009},
  author = {Fabrigar, Leandre R. and Wegener, Duane T.},
  month = sep,
  year = {2016},
  keywords = {Psychometrics,meta-analysis,Replication},
  pages = {68-80},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\9QFKHUJ5\\Fabrigar_Wegener_2016_Conceptualizing and evaluating the replication of research results.pdf;C:\\Users\\lissa102\\Zotero\\storage\\SM2ADJ7I\\S0022103115000967.html}
}

@article{braverContinuouslyCumulatingMetaAnalysis2014,
  title = {Continuously {{Cumulating Meta}}-{{Analysis}} and {{Replicability}}},
  volume = {9},
  issn = {1745-6916},
  abstract = {The current crisis in scientific psychology about whether our findings are irreproducible was presaged years ago by Tversky and Kahneman (1971), who noted that even sophisticated researchers believe in the fallacious Law of Small Numbers\textemdash{}erroneous intuitions about how imprecisely sample data reflect population phenomena. Combined with the low power of most current work, this often leads to the use of misleading criteria about whether an effect has replicated. Rosenthal (1990) suggested more appropriate criteria, here labeled the continuously cumulating meta-analytic (CCMA) approach. For example, a CCMA analysis on a replication attempt that does not reach significance might nonetheless provide more, not less, evidence that the effect is real. Alternatively, measures of heterogeneity might show that two studies that differ in whether they are significant might have only trivially different effect sizes. We present a nontechnical introduction to the CCMA framework (referencing relevant software), and then explain how it can be used to address aspects of replicability or more generally to assess quantitative evidence from numerous studies. We then present some examples and simulation results using the CCMA approach that show how the combination of evidence can yield improved results over the consideration of single studies.},
  language = {en},
  number = {3},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691614529796},
  author = {Braver, Sanford L. and Thoemmes, Felix J. and Rosenthal, Robert},
  month = may,
  year = {2014},
  pages = {333-342},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\A89KTA9G\\Braver et al_2014_Continuously Cumulating Meta-Analysis and Replicability.pdf}
}

@article{hedgesFixedRandomeffectsModels1998,
  title = {Fixed- and {{Random}}-Effects {{Models}} in {{Meta}}-Analysis},
  volume = {3},
  issn = {1082-989X},
  abstract = {There are 2 families of statistical procedures in meta-analysis: fixed- and random-effects procedures. They were developed for somewhat different inference goals: making inferences about the effect parameters in the studies that have been observed versus making inferences about the distribution of effect parameters in a population of studies from a random sample of studies. The authors evaluate the performance of confidence intervals and hypothesis tests when each type of statistical procedure is used for each type of inference and confirm that each procedure is best for making the kind of inference for which it was designed. Conditionally random-effects procedures (a hybrid type) are shown to have properties in between those of fixed- and random-effects procedures.},
  language = {ENGLISH},
  number = {4},
  journal = {Psychological Methods},
  author = {Hedges, Larry V. and Vevea, Jack L.},
  year = {1998},
  pages = {486-504},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\5JJARYLR\\Hedges and Vevea - 1998 - Fixed- and Random-effects Models in Meta-analysis.pdf;C:\\Users\\lissa102\\Zotero\\storage\\GIXWMJKR\\00060744.html},
  pmid = {00060744-199812000-00006}
}

@incollection{gigerenzerNullRitualWhat2004,
  address = {{Thousand Oaks}},
  title = {The Null Ritual : {{What}} You Always Wanted to Know about Significance Testing but Were Afraid to Ask},
  isbn = {978-0-7619-2359-6},
  shorttitle = {The Null Ritual},
  language = {eng},
  booktitle = {The {{Sage}} Handbook of Quantitative Methodology for the Social Sciences},
  publisher = {{Sage}},
  author = {Gigerenzer, Gerd and Krauss, Stefan and Vitouch, Oliver},
  editor = {Kaplan, David},
  year = {2004},
  pages = {391--408},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\AW4645E4\\GG_Null_2004.pdf}
}

@article{hedgesDistributionTheoryGlass1981,
  title = {Distribution {{Theory}} for {{Glass}}'s {{Estimator}} of {{Effect Size}} and {{Related Estimators}}},
  volume = {6},
  abstract = {Glass's estimator of effect size, the sample mean difference divided by the sample standard deviation, is studied in the context of an explicit statistical model. The exact distribution of Glass's estimator is obtained and the estimator is shown to have a small sample bias. Alternatives are proposed and discussed. (Author/JKS)},
  language = {en},
  number = {2},
  journal = {Journal of Educational Statistics},
  author = {Hedges, Larry V.},
  year = {1981/00/00},
  keywords = {Research Design,Error of Measurement,Data Analysis,Mathematical Models,Statistical Distributions,Validity},
  pages = {107-28},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\URWMXSKB\\eric.ed.gov.html}
}

@article{wagenmakersBayesianInferencePsychology2017,
  title = {Bayesian Inference for Psychology. {{Part I}}: {{Theoretical}} Advantages and Practical Ramifications},
  shorttitle = {Bayesian Inference for Psychology. {{Part I}}},
  journal = {Psychonomic Bulletin \& Review},
  author = {Wagenmakers, Eric-Jan and Marsman, Maarten and Jamil, Tahira and Ly, Alexander and Verhagen, Josine and Love, Jonathon and Selker, Ravi and Gronau, Quentin F. and {\v S}m{\'i}ra, Martin and Epskamp, Sacha and others},
  year = {2017},
  pages = {1--23},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\CXVT4CT7\\BayesianInferenceForPsychologyPartI.pdf}
}

@article{viechtbauerConfidenceIntervalsAmount2007,
  title = {Confidence Intervals for the Amount of Heterogeneity in Meta-Analysis},
  volume = {26},
  issn = {02776715, 10970258},
  language = {en},
  number = {1},
  journal = {Statistics in Medicine},
  doi = {10.1002/sim.2514},
  author = {Viechtbauer, Wolfgang},
  month = jan,
  year = {2007},
  pages = {37-52},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\P9THIXQH\\viechtbauer2006.pdf}
}

@misc{PublicationsWhyUpload,
  title = {Publications - {{Why}} Upload to Academic Preprint Sites like {{arXiv}}? - {{Academia Stack Exchange}}},
  shorttitle = {Publications - {{Why}} Upload to Academic Preprint Sites like {{arXiv}}?},
  howpublished = {https://academia.stackexchange.com/questions/16832/why-upload-to-academic-preprint-sites-like-arxiv},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\Q7VJT5RX\\why-upload-to-academic-preprint-sites-like-arxiv.html}
}

@misc{ImportantModelEvaluation2016,
  title = {7 {{Important Model Evaluation Error Metrics Everyone}} Should Know},
  abstract = {This article explains different evaluation metrics used in predictive model with k fold cross validation technique for bias variance tradeoff},
  journal = {Analytics Vidhya},
  month = feb,
  year = {2016},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\R7S9HEQA\\7-important-model-evaluation-error-metrics.html}
}

@article{cesarioPrimingReplicationHardest2014,
  title = {Priming, {{Replication}}, and the {{Hardest Science}}},
  volume = {9},
  issn = {1745-6916},
  abstract = {Concerns have been raised recently about the replicability of behavioral priming effects, and calls have been issued to identify priming methodologies with effects that can be obtained in any context and with any population. I argue that such expectations are misguided and inconsistent with evolutionary understandings of the brain as a computational organ. Rather, we should expect priming effects to be highly sensitive to variations in experimental features and subject populations. Such variation does not make priming effects frivolous or capricious but instead can be predicted a priori. However, absent theories specifying the precise contingencies that lead to such variation, failures to replicate another researcher's findings will necessarily be ambiguous with respect to the inferences that can be made. Priming research is not yet at the stage where such theories exist, and therefore failures are uninformative at the current time. Ultimately, priming researchers themselves must provide direct replications of their own effects; researchers have been deficient in meeting this responsibility and have contributed to the current state of confusion. The recommendations issued in this article reflect concerns both with the practice of priming researchers and with the inappropriate expectations of researchers who have failed to replicate others' priming effects.},
  language = {en},
  number = {1},
  journal = {Perspectives on Psychological Science},
  doi = {10.1177/1745691613513470},
  author = {Cesario, Joseph},
  month = jan,
  year = {2014},
  pages = {40-48},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\UKW9UWTW\\Cesario_2014_Priming, Replication, and the Hardest Science.pdf}
}

@article{dersimonianMetaanalysisClinicalTrials1986,
  title = {Meta-Analysis in Clinical Trials},
  volume = {7},
  issn = {0197-2456},
  abstract = {This paper examines eight published reviews each reporting results from several related trials. Each review pools the results from the relevant trials in order to evaluate the efficacy of a certain treatment for a specified medical condition. These reviews lack consistent assessment of homogeneity of treatment effect before pooling. We discuss a random effects approach to combining evidence from a series of experiments comparing two treatments. This approach incorporates the heterogeneity of effects in the analysis of the overall treatment efficacy. The model can be extended to include relevant covariates which would reduce the heterogeneity and allow for more specific therapeutic recommendations. We suggest a simple noniterative procedure for characterizing the distribution of treatment effects in a series of studies.},
  number = {3},
  journal = {Controlled Clinical Trials},
  doi = {10.1016/0197-2456(86)90046-2},
  author = {DerSimonian, Rebecca and Laird, Nan},
  month = sep,
  year = {1986},
  keywords = {covariate information,distribution of treatment effects,heterogeneity of treatment effects,random effects model},
  pages = {177-188},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\TF6GVR7H\\0197245686900462.html}
}

@article{simmonsFalsePositivePsychologyUndisclosed2011,
  title = {False-{{Positive Psychology}}: {{Undisclosed Flexibility}} in {{Data Collection}} and {{Analysis Allows Presenting Anything}} as {{Significant}}},
  volume = {22},
  issn = {0956-7976},
  shorttitle = {False-{{Positive Psychology}}},
  abstract = {In this article, we accomplish two things. First, we show that despite empirical psychologists' nominal endorsement of a low rate of false-positive findings ({$\leq$} .05), flexibility in data collection, analysis, and reporting dramatically increases actual false-positive rates. In many cases, a researcher is more likely to falsely find evidence that an effect exists than to correctly find evidence that it does not. We present computer simulations and a pair of actual experiments that demonstrate how unacceptably easy it is to accumulate (and report) statistically significant evidence for a false hypothesis. Second, we suggest a simple, low-cost, and straightforwardly effective disclosure-based solution to this problem. The solution involves six concrete requirements for authors and four guidelines for reviewers, all of which impose a minimal burden on the publication process.},
  language = {en},
  number = {11},
  journal = {Psychological Science},
  doi = {10.1177/0956797611417632},
  author = {Simmons, Joseph P. and Nelson, Leif D. and Simonsohn, Uri},
  month = nov,
  year = {2011},
  pages = {1359-1366},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\875T36B3\\Simmons et al_2011_False-Positive Psychology.pdf}
}

@article{earpReplicationFalsificationCrisis2015,
  title = {Replication, Falsification, and the Crisis of Confidence in Social Psychology},
  volume = {6},
  issn = {1664-1078},
  abstract = {The (latest) crisis in confidence in social psychology has generated much heated discussion about the importance of replication, including how it should be carried out as well as interpreted by scholars in the field. For example, what does it mean if a replication attempt ``fails''\textemdash{}does it mean that the original results, or the theory that predicted them, have been falsified? And how should ``failed'' replications affect our belief in the validity of the original research? In this paper, we consider the replication debate from a historical and philosophical perspective, and provide a conceptual analysis of both replication and falsification as they pertain to this important discussion. Along the way, we highlight the importance of auxiliary assumptions (for both testing theories and attempting replications), and introduce a Bayesian framework for assessing ``failed'' replications in terms of how they should affect our confidence in original findings.},
  journal = {Frontiers in Psychology},
  doi = {10.3389/fpsyg.2015.00621},
  author = {Earp, Brian D. and Trafimow, David},
  month = may,
  year = {2015},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\KB3CBMH6\\Earp_Trafimow_2015_Replication, falsification, and the crisis of confidence in social psychology.pdf},
  pmid = {26042061},
  pmcid = {PMC4436798}
}

@article{maxwellPsychologySufferingReplication2015,
  title = {Is Psychology Suffering from a Replication Crisis? {{What}} Does ``Failure to Replicate'' Really Mean?},
  volume = {70},
  issn = {1935-990X, 0003-066X},
  shorttitle = {Is Psychology Suffering from a Replication Crisis?},
  language = {en},
  number = {6},
  journal = {American Psychologist},
  doi = {10.1037/a0039400},
  author = {Maxwell, Scott E. and Lau, Michael Y. and Howard, George S.},
  year = {2015},
  pages = {487-498},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\BWNDKHTZ\\maxwell2015.pdf}
}

@article{wrightRangerFastImplementation2015,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1508.04409},
  primaryClass = {stat},
  title = {Ranger: {{A Fast Implementation}} of {{Random Forests}} for {{High Dimensional Data}} in {{C}}++ and {{R}}},
  shorttitle = {Ranger},
  abstract = {We introduce the C++ application and R package ranger. The software is a fast implementation of random forests for high dimensional data. Ensembles of classification, regression and survival trees are supported. We describe the implementation, provide examples, validate the package with a reference implementation, and compare runtime and memory usage with other implementations. The new software proves to scale best with the number of features, samples, trees, and features tried for splitting. Finally, we show that ranger is the fastest and most memory efficient implementation of random forests to analyze data on the scale of a genome-wide association study.},
  journal = {arXiv:1508.04409 [stat]},
  author = {Wright, Marvin N. and Ziegler, Andreas},
  month = aug,
  year = {2015},
  keywords = {Statistics - Computation,Statistics - Machine Learning},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\2QCM8EU7\\Wright_Ziegler_2015_ranger.pdf;C:\\Users\\lissa102\\Zotero\\storage\\W7MZ7V4J\\1508.html}
}

@article{heinzeFiveMythsVariable2017,
  title = {Five Myths about Variable Selection},
  volume = {30},
  issn = {09340874},
  abstract = {Multivariable regression models are often used in transplantation research to identify or to confirm baseline variables which have an independent association, causally or only evidenced by statistical correlation, with transplantation outcome. Although sound theory is lacking, variable selection is a popular statistical method which seemingly reduces the complexity of such models. However, in fact, variable selection often complicates analysis as it invalidates common tools of statistical inference such as P-values and confidence intervals. This is a particular problem in transplantation research where sample sizes are often only small to moderate. Furthermore, variable selection requires computer-intensive stability investigations and a particularly cautious interpretation of results. We discuss how five common misconceptions often lead to inappropriate application of variable selection. We emphasize that variable selection and all problems related with it can often be avoided by the use of expert knowledge.},
  language = {en},
  number = {1},
  journal = {Transplant International},
  doi = {10.1111/tri.12895},
  author = {Heinze, Georg and Dunkler, Daniela},
  month = jan,
  year = {2017},
  pages = {6-10},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\G5RIYV57\\Heinze and Dunkler - 2017 - Five myths about variable selection.pdf}
}

@book{good2004permutation,
  address = {{New York, NY}},
  edition = {3},
  title = {Permutation, Parametric, and Bootstrap Tests of Hypotheses},
  author = {Good, Phillip},
  year = {2005},
  publisher = {{Springer New York}}
}

@article{ioannidisMassProductionRedundant2016,
  title = {The {{Mass Production}} of {{Redundant}}, {{Misleading}}, and {{Conflicted Systematic Reviews}} and {{Meta}}-Analyses: {{Mass Production}} of {{Systematic Reviews}} and {{Meta}}-Analyses},
  volume = {94},
  issn = {0887378X},
  shorttitle = {The {{Mass Production}} of {{Redundant}}, {{Misleading}}, and {{Conflicted Systematic Reviews}} and {{Meta}}-Analyses},
  language = {en},
  number = {3},
  journal = {The Milbank Quarterly},
  doi = {10.1111/1468-0009.12210},
  author = {Ioannidis, John P.A.},
  month = sep,
  year = {2016},
  pages = {485-514},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\BI4HL636\\Ioannidis - 2016 - The Mass Production of Redundant, Misleading, and .pdf}
}

@article{bornmannGrowthRatesModern2015,
  title = {Growth Rates of Modern Science: {{A}} Bibliometric Analysis Based on the Number of Publications and Cited References},
  volume = {66},
  copyright = {\textcopyright{}2013, Midwest Political Science Association},
  issn = {2330-1643},
  shorttitle = {Growth Rates of Modern Science},
  abstract = {Many studies (in information science) have looked at the growth of science. In this study, we reexamine the question of the growth of science. To do this we (a) use current data up to publication year 2012 and (b) analyze the data across all disciplines and also separately for the natural sciences and for the medical and health sciences. Furthermore, the data were analyzed with an advanced statistical technique\textemdash{}segmented regression analysis\textemdash{}which can identify specific segments with similar growth rates in the history of science. The study is based on two different sets of bibliometric data: (a) the number of publications held as source items in the Web of Science (WoS, Thomson Reuters) per publication year and (b) the number of cited references in the publications of the source items per cited reference year. We looked at the rate at which science has grown since the mid-1600s. In our analysis of cited references we identified three essential growth phases in the development of science, which each led to growth rates tripling in comparison with the previous phase: from less than 1\% up to the middle of the 18th century, to 2 to 3\% up to the period between the two world wars, and 8 to 9\% to 2010.},
  language = {en},
  number = {11},
  journal = {Journal of the Association for Information Science and Technology},
  doi = {10.1002/asi.23329},
  author = {Bornmann, Lutz and Mutz, R{\"u}diger},
  year = {2015},
  keywords = {bibliometrics},
  pages = {2215-2222},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GSS2E64N\\Bornmann and Mutz - 2014 - Growth rates of modern science A bibliometric ana.pdf;C:\\Users\\lissa102\\Zotero\\storage\\XYMTFXXR\\Bornmann and Mutz - 2015 - Growth rates of modern science A bibliometric ana.pdf;C:\\Users\\lissa102\\Zotero\\storage\\WJIH5QIE\\asi.html}
}

@article{crocettiSystematicReviewsMetaAnalysis2016,
  title = {Systematic {{Reviews With Meta}}-{{Analysis}}: {{Why}}, {{When}}, and {{How}}?},
  volume = {4},
  issn = {2167-6968},
  shorttitle = {Systematic {{Reviews With Meta}}-{{Analysis}}},
  abstract = {Systematic reviews with meta-analysis represent the gold standard for conducting reliable and transparent reviews of the literature. The purpose of this article is threefold: (a) to address why and when it is worthwhile to conduct a systematic review with meta-analysis, covering advantages of this approach in the context of the statistics reform in the behavioral sciences; (b) to explain how to conduct and publish a systematic review with meta-analysis, describe the main steps, and suggest best practices for each of them; and (c) to discuss the relevance of conducting a systematic review with meta-analysis for the emerging adulthood field, suggesting how this approach can be applied to address research questions about the specificity of this period. In addressing these issues, a fictitious systematic review with meta-analysis aimed at examining gender differences in the view of emerging adulthood as a period of exploration, instability, self-focus, feeling-in-between, and possibilities is presented. Furthermore, individual participant data systematic review with meta-analysis is proposed as an important future direction for conducting reviews within the social sciences.},
  language = {en},
  number = {1},
  journal = {Emerging Adulthood},
  doi = {10.1177/2167696815617076},
  author = {Crocetti, Elisabetta},
  month = feb,
  year = {2016},
  pages = {3-18}
}

@article{nosekPromotingOpenResearch2015,
  title = {Promoting an Open Research Culture},
  volume = {348},
  copyright = {Copyright \textcopyright{} 2015, American Association for the Advancement of Science},
  issn = {0036-8075, 1095-9203},
  abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility
Author guidelines for journals could help to promote transparency, openness, and reproducibility},
  language = {en},
  number = {6242},
  journal = {Science},
  doi = {10.1126/science.aab2374},
  author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and {Mayo-Wilson}, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
  month = jun,
  year = {2015},
  pages = {1422-1425},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\QMIA9CDD\\Nosek et al. - 2015 - Promoting an open research culture.pdf;C:\\Users\\lissa102\\Zotero\\storage\\CHZTCVV2\\1422.html},
  pmid = {26113702}
}

@misc{vanlissaMetaforestExploringHeterogeneity2018,
  title = {Metaforest: {{Exploring Heterogeneity}} in {{Meta}}-{{Analysis}} Using {{Random Forests}}},
  author = {Van Lissa, Caspar J.},
  year = {2018}
}

@article{jongeMetaMetaAnalysisIdentifyingTypical2018,
  title = {A {{Meta}}-{{Meta}}-{{Analysis}}: {{Identifying Typical Conditions}} of {{Meta}}-{{Analyses}} in {{Educational Research}}},
  shorttitle = {A {{Meta}}-{{Meta}}-{{Analysis}}},
  abstract = {Thesis | Research Master Child Development and Education | University of Amsterdam, the Netherlands | Student: H. de Jonge | Supervisor: dr. S. Jak  
    Hosted on the Open Science Framework},
  language = {en},
  doi = {10.17605/OSF.IO/ZAU68},
  author = {de Jonge, Hannelies and Jak, Suzanne},
  month = jul,
  year = {2018},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\M7YM38MF\\zau68.html}
}

@misc{mayerMissRangerFastImputation2019,
  title = {{{missRanger}}: {{Fast Imputation}} of {{Missing Values}}},
  author = {Mayer, Michael},
  year = {2019}
}

@article{liberatiPRISMAStatementReporting2009,
  title = {The {{PRISMA Statement}} for {{Reporting Systematic Reviews}} and {{Meta}}-{{Analyses}} of {{Studies That Evaluate Health Care Interventions}}: {{Explanation}} and {{Elaboration}}},
  volume = {6},
  issn = {1549-1676},
  shorttitle = {The {{PRISMA Statement}} for {{Reporting Systematic Reviews}} and {{Meta}}-{{Analyses}} of {{Studies That Evaluate Health Care Interventions}}},
  abstract = {Systematic reviews and meta-analyses are essential to summarize evidence relating to efficacy and safety of health care interventions accurately and reliably. The clarity and transparency of these reports, however, is not optimal. Poor reporting of systematic reviews diminishes their value to clinicians, policy makers, and other users. Since the development of the QUOROM (QUality Of Reporting Of Meta-analysis) Statement\textemdash{}a reporting guideline published in 1999\textemdash{}there have been several conceptual, methodological, and practical advances regarding the conduct and reporting of systematic reviews and meta-analyses. Also, reviews of published systematic reviews have found that key information about these studies is often poorly reported. Realizing these issues, an international group that included experienced authors and methodologists developed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) as an evolution of the original QUOROM guideline for systematic reviews and meta-analyses of evaluations of health care interventions. The PRISMA Statement consists of a 27-item checklist and a four-phase flow diagram. The checklist includes items deemed essential for transparent reporting of a systematic review. In this Explanation and Elaboration document, we explain the meaning and rationale for each checklist item. For each item, we include an example of good reporting and, where possible, references to relevant empirical studies and methodological literature. The PRISMA Statement, this document, and the associated Web site (http://www. prisma-statement.org/) should be helpful resources to improve reporting of systematic reviews and metaanalyses.},
  language = {en},
  number = {7},
  journal = {PLoS Medicine},
  doi = {10.1371/journal.pmed.1000100},
  author = {Liberati, Alessandro and Altman, Douglas G. and Tetzlaff, Jennifer and Mulrow, Cynthia and G{\o}tzsche, Peter C. and Ioannidis, John P. A. and Clarke, Mike and Devereaux, P. J. and Kleijnen, Jos and Moher, David},
  month = jul,
  year = {2009},
  pages = {e1000100},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\LNU7JX7L\\Liberati et al. - 2009 - The PRISMA Statement for Reporting Systematic Revi.pdf}
}

@book{wingCaretClassificationRegression2018,
  title = {Caret: {{Classification}} and {{Regression Training}}},
  author = {Wing, Max Kuhn Contributions from Jed and Weston, Steve and Williams, Andre and Keefer, Chris and Engelhardt, Allan and Cooper, Tony and Mayer, Zachary and Kenkel, Brenton and Team, the R. Core and Benesty, Michael and Lescarbeau, Reynald and Ziem, Andrew and Scrucca, Luca and Tang, Yuan and Candan, Can and Hunt, Tyler},
  year = {2018}
}

@article{JSSv028i05,
  title = {Building {{Predictive Models}} in {{R Using}} the Caret {{Package}}},
  volume = {28},
  issn = {1548-7660},
  abstract = {The caret package, short for classification and regression training, contains numerous tools for developing predictive models using the rich set of models available in R. The package focuses on simplifying model training and tuning across a wide variety of modeling techniques. It also includes methods for pre-processing training data, calculating variable importance, and model visualizations. An example from computational chemistry is used to illustrate the functionality on a real data set and to benchmark the benefits of parallel processing with several types of models.},
  number = {5},
  journal = {Journal of Statistical Software, Articles},
  doi = {10.18637/jss.v028.i05},
  author = {Kuhn, Max},
  year = {2008},
  pages = {1-26}
}

@article{fukkinkDoesTrainingMatter2007,
  title = {Does Training Matter? {{A}} Meta-Analysis and Review of Caregiver Training Studies},
  volume = {22},
  issn = {08852006},
  shorttitle = {Does Training Matter?},
  abstract = {A review of studies published between 1980 and 2005 shows a significant positive effect of specialized training on the competency of caregivers in childcare (d = 0.45, S.E. = 0.10). Experimental results from the meta-analysis were significantly smaller for settings with no fixed curriculum content, delivery of the training at multiple sites and large-scale programs. Results were also smaller when tests were used that did not align closely with the content of the training. Furthermore, experimental results were smaller for the skills domain, compared to the knowledge and attitude domain. A subset of experiments with both caregiver and child data also showed a positive effect, supporting the causal link between caregiver training, caregiver competencies and child behavior in childcare, although this effect was not significant due to the small number of studies (d = 0.55, S.E. = 0.30). Based on these findings, we advocate the inclusion of instruction related to teacher\textendash{}child interaction in the curriculum of vocational training for caregivers. \textcopyright{} 2007 Elsevier Inc. All rights reserved.},
  language = {en},
  number = {3},
  journal = {Early Childhood Research Quarterly},
  doi = {10.1016/j.ecresq.2007.04.005},
  author = {Fukkink, Ruben G. and Lont, Anna},
  month = jul,
  year = {2007},
  pages = {294-311},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\GNFHJ6UE\\Fukkink and Lont - 2007 - Does training matter A meta-analysis and review o.pdf}
}

@article{vansebilleGlobalInventorySmall2015,
  title = {A Global Inventory of Small Floating Plastic Debris},
  volume = {10},
  issn = {1748-9326},
  abstract = {Microplastic debris floating at the ocean surface can harm marine life. Understanding the severity of this harm requires knowledge of plastic abundance and distributions. Dozens of expeditions measuring microplastics have been carried out since the 1970s, but they have primarily focused on the North Atlantic and North Pacific accumulation zones, with much sparser coverage elsewhere. Here, we use the largest dataset of microplastic measurements assembled to date to assess the confidence we can have in global estimates of microplastic abundance and mass. We use a rigorous statistical framework to standardize a global dataset of plastic marine debris measured using surface-trawling plankton nets and coupled this with three different ocean circulation models to spatially interpolate the observations. Our estimates show that the accumulated number of microplastic particles in 2014 ranges from 15 to 51 trillion particles, weighing between 93 and 236 thousand metric tons, which is only approximately 1\% of global plastic waste estimated to enter the ocean in the year 2010. These estimates are larger than previous global estimates, but vary widely because the scarcity of data in most of the world ocean, differences in model formulations, and fundamental knowledge gaps in the sources, transformations and fates of microplastics in the ocean.},
  language = {en},
  number = {12},
  journal = {Environmental Research Letters},
  doi = {10.1088/1748-9326/10/12/124006},
  author = {{van Sebille}, Erik and Wilcox, Chris and Lebreton, Laurent and Maximenko, Nikolai and Hardesty, Britta Denise and {van Franeker}, Jan A and Eriksen, Marcus and Siegel, David and Galgani, Francois and Law, Kara Lavender},
  month = dec,
  year = {2015},
  pages = {124006},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\MEQ4A7Q7\\van Sebille et al. - 2015 - A global inventory of small floating plastic debri.pdf}
}

@article{bonapersonaBehavioralPhenotypeEarly2019,
  title = {The Behavioral Phenotype of Early Life Adversity: A 3-Level Meta-Analysis of Rodent Studies: {{Supplemental Material}}},
  shorttitle = {The Behavioral Phenotype of Early Life Adversity},
  abstract = {Background. Altered cognitive performance has been suggested as an intermediate phenotype mediating the effects of early life adversity (ELA) on later-life development of mental disorders, e.g. depression. Whereas most human studies are limited to correlational conclusions, rodent studies can prospectively investigate how ELA alters cognitive performance in a number of domains. Despite the vast volume of reports, no consensus has yet been reached on the i) behavioral domains being affected by ELA and ii) the extent of these effects.
Methods. To test how ELA (here: aberrant maternal care) affects specific behavioral domains, we used a 3-level mixed-effect meta-analysis, a flexible model that accounts for the dependency of observations. We thoroughly explored heterogeneity with MetaForest, a machine-learning data-driven analysis never applied before in preclinical literature. We validated the robustness of our findings with substantial sensitivity analyses and bias assessments.
Results. Our results, based on {$>$}400 independent experiments, yielded {$>$}700 comparisons, involving \textasciitilde{}8600 animals. Especially in males, ELA promotes memory formation during stressful learning but impairs non-stressful learning. Furthermore, ELA increases anxiety and decreases social behavior. The ELA phenotype was strongest when i) combined with other negative experiences (``hits''); ii) in rats; iii) in ELA models of \textasciitilde{}10days duration.
Conclusion. Prospective and well-controlled animal studies demonstrate that ELA durably and differentially impacts distinct behavioral domains. All data is now easily accessible with MaBapp (https://osf.io/ra947/), which allows researchers to run tailor-made meta-analyses on the topic, thereby revealing the optimal choice of experimental protocols and study power.},
  language = {en},
  journal = {bioRxiv},
  doi = {10.1101/521245},
  author = {Bonapersona, Valeria and Kentrop, Jiska and Van Lissa, Caspar J and {van der Veen}, Rixt and Joels, Marian and Sarabdjitsingh, Ratna Angela},
  month = jan,
  year = {2019},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\CEI4LB9K\\Bonapersona et al. - 2019 - The behavioral phenotype of early life adversity .pdf}
}

@article{gaoyajingOwningLeadsValuing2018,
  title = {Owning Leads to Valuing: {{Meta}}-Analysis of the {{Mere Ownership Effect}}},
  shorttitle = {Owning Leads to Valuing},
  abstract = {Mere ownership effect is the phenomenon that people tend to value what they own more than what they do not own. This classic effect is considered robust, yet evidence is inconsistent, effect size varies across studies, and the effect is often confused for or confounded with other classic phenomena, such as endowment or mere exposure effects. We conducted a pre-registered metaanalysis of 26 samples (N = 3132) resulting in medium effect-size for psychological ownership on valuing (g = 0.59, 95\% confidence intervals [CI] [0.47, 0.70]). Moderator analyses showed that object materiality, use of replica, and valuing type were the strongest moderators, compared to weaker effects for loss aversion, type of ownership (implicit/explicit), level of exposure, and study design (between/within). Mere ownership effects were different than null across all moderator categories and publication bias corrections. We conclude that psychological owning indeed leads to valuing, regardless of endowment, loss-aversion, and mere-exposure effects.},
  language = {en},
  journal = {Unpublished},
  doi = {10.13140/rg.2.2.13568.33287/1},
  author = {{Gao, Yajing} and Yao, Donna and Feldman, Gilad},
  year = {2018},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\J8B2F7ZR\\Yajing Gao et al. - 2018 - Owning leads to valuing Meta-analysis of the Mere.pdf}
}

@article{curryHappyHelpSystematic2018,
  title = {Happy to Help? {{A}} Systematic Review and Meta-Analysis of the Effects of Performing Acts of Kindness on the Well-Being of the Actor},
  volume = {76},
  issn = {0022-1031},
  shorttitle = {Happy to Help?},
  abstract = {Do acts of kindness improve the well-being of the actor? Recent advances in the behavioural sciences have provided a number of explanations of human social, cooperative and altruistic behaviour. These theories predict that people will be `happy to help' family, friends, community members, spouses, and even strangers under some conditions. Here we conduct a systematic review and meta-analysis of the experimental evidence that kindness interventions (for example, performing `random acts of kindness') boost subjective well-being. Our initial search of the literature identified 489 articles; of which 24 (27 studies) met the inclusion criteria (total N = 4045). These 27 studies, some of which included multiple control conditions and dependent measures, yielded 52 effect sizes. Multi-level modeling revealed that the overall effect of kindness on the well-being of the actor is small-to-medium ({$\delta$} = 0.28). The effect was not moderated by sex, age, type of participant, intervention, control condition or outcome measure. There was no indication of publication bias. We discuss the limitations of the current literature, and recommend that future research test more specific theories of kindness: taking kindness-specific individual differences into account; distinguishing between the effects of kindness to specific categories of people; and considering a wider range of proximal and distal outcomes. Such research will advance our understanding of the causes and consequences of kindness, and help practitioners to maximise the effectiveness of kindness interventions to improve well-being.},
  journal = {Journal of Experimental Social Psychology},
  doi = {10.1016/j.jesp.2018.02.014},
  author = {Curry, Oliver Scott and Rowland, Lee A. and Van Lissa, Caspar J. and Zlotowitz, Sally and McAlaney, John and Whitehouse, Harvey},
  month = may,
  year = {2018},
  keywords = {Altruism,Happiness,Kindness,Positive psychology,Well-being},
  pages = {320-329},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\4BR23U9D\\Curry et al. - 2018 - Happy to help A systematic review and meta-analys.pdf;C:\\Users\\lissa102\\Zotero\\storage\\4IMQUNVM\\S0022103117303451.html}
}

@article{panityakulEstimatingResidualHeterogeneity2013,
  title = {On {{Estimating Residual Heterogeneity}} in {{Random}}-{{Effects Meta}}-{{Regression}}: {{A Comparative Study}}},
  volume = {12},
  issn = {1538-7887},
  shorttitle = {On {{Estimating Residual Heterogeneity}} in {{Random}}-{{Effects Meta}}-{{Regression}}},
  abstract = {We consider six different estimators of residual heterogeneity in random-effects meta-regression, five estimators already known and implemented in the R package metaphor and one estimator not yet considered in random-effects meta-regression. In a numerical study, we investigate the properties of these residual heterogeneity estimators as well as the...},
  language = {en},
  number = {3},
  journal = {Journal of Statistical Theory and Applications},
  doi = {10.2991/jsta.2013.12.3.4},
  author = {Panityakul, Thammarat and Bumrungsup, Chinnaphong and Knapp, Guido},
  month = sep,
  year = {2013},
  pages = {253-265},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\RHRGDFFC\\Panityakul et al. - 2013 - On Estimating Residual Heterogeneity in Random-Eff.pdf;C:\\Users\\lissa102\\Zotero\\storage\\A63CRE5X\\9049.html}
}

@article{probstHyperparametersTuningStrategies2019,
  archivePrefix = {arXiv},
  eprinttype = {arxiv},
  eprint = {1804.03515},
  title = {Hyperparameters and {{Tuning Strategies}} for {{Random Forest}}},
  issn = {19424787},
  abstract = {The random forest algorithm (RF) has several hyperparameters that have to be set by the user, e.g., the number of observations drawn randomly for each tree and whether they are drawn with or without replacement, the number of variables drawn randomly for each split, the splitting rule, the minimum number of samples that a node must contain and the number of trees. In this paper, we first provide a literature review on the parameters' influence on the prediction performance and on variable importance measures. It is well known that in most cases RF works reasonably well with the default values of the hyperparameters specified in software packages. Nevertheless, tuning the hyperparameters can improve the performance of RF. In the second part of this paper, after a brief overview of tuning strategies we demonstrate the application of one of the most established tuning strategies, model-based optimization (MBO). To make it easier to use, we provide the tuneRanger R package that tunes RF with MBO automatically. In a benchmark study on several datasets, we compare the prediction performance and runtime of tuneRanger with other tuning implementations in R and RF with default hyperparameters.},
  journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  doi = {10.1002/widm.1301},
  author = {Probst, Philipp and Wright, Marvin and Boulesteix, Anne-Laure},
  month = jan,
  year = {2019},
  keywords = {Statistics - Machine Learning,Computer Science - Machine Learning},
  pages = {e1301},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\Y629SQ3D\\Probst et al. - 2019 - Hyperparameters and Tuning Strategies for Random F.pdf;C:\\Users\\lissa102\\Zotero\\storage\\JDEWYBUH\\1804.html}
}

@book{cheung2015meta,
  address = {{West Sussex, United Kingdom}},
  title = {Meta-Analysis: {{A}} Structural Equation Modeling Approach},
  isbn = {978-1-119-99343-8},
  publisher = {{John Wiley \& Sons}},
  author = {Cheung, Mike W-L},
  year = {2015}
}

@article{pustejovskySmallSampleMethodsClusterRobust2018,
  title = {Small-{{Sample Methods}} for {{Cluster}}-{{Robust Variance Estimation}} and {{Hypothesis Testing}} in {{Fixed Effects Models}}},
  volume = {36},
  issn = {0735-0015},
  abstract = {In panel data models and other regressions with unobserved effects, fixed effects estimation is often paired with cluster-robust variance estimation (CRVE) to account for heteroscedasticity and un-modeled dependence among the errors. Although asymptotically consistent, CRVE can be biased downward when the number of clusters is small, leading to hypothesis tests with rejection rates that are too high. More accurate tests can be constructed using bias-reduced linearization (BRL), which corrects the CRVE based on a working model, in conjunction with a Satterthwaite approximation for t-tests. We propose a generalization of BRL that can be applied in models with arbitrary sets of fixed effects, where the original BRL method is undefined, and describe how to apply the method when the regression is estimated after absorbing the fixed effects. We also propose a small-sample test for multiple-parameter hypotheses, which generalizes the Satterthwaite approximation for t-tests. In simulations covering a wide range of scenarios, we find that the conventional cluster-robust Wald test can severely over-reject while the proposed small-sample test maintains Type I error close to nominal levels. The proposed methods are implemented in an R package called clubSandwich. This article has online supplementary materials.},
  number = {4},
  journal = {Journal of Business \& Economic Statistics},
  doi = {10.1080/07350015.2016.1247004},
  author = {Pustejovsky, James E. and Tipton, Elizabeth},
  month = oct,
  year = {2018},
  pages = {672-683},
  file = {C:\\Users\\lissa102\\Zotero\\storage\\R7SETZLV\\Pustejovsky and Tipton - 2018 - Small-Sample Methods for Cluster-Robust Variance E.pdf;C:\\Users\\lissa102\\Zotero\\storage\\3RU5W6K6\\07350015.2016.html}
}


